{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385265fd",
   "metadata": {},
   "source": [
    "# Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956f6a20",
   "metadata": {},
   "source": [
    "The csv file \"classdata/Aircraft Incidents.csv\" contains the investigation reports by the National Transportation Safety Board (NTSB) for all airline incidents in 2011. \n",
    "\n",
    "- Column \"Final Narrative\" gives the final description of each accident and its probable cause. \n",
    "- Column \"Fatal\" indicates if there was any fatality in each accident. \n",
    "\n",
    "The following code reads the data and shows the frequencies of the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73841267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Non-Fatal    1554\n",
       "Fatal         352\n",
       "Name: Fatal, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"classdata/Aircraft Incidents.csv\")\n",
    "df.Fatal.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a24cf1c",
   "metadata": {},
   "source": [
    "1. Partition **df** into training (70%) and testing (30%) sets as new dataframes. Convert column \"Final Narrative\" in each set to a DTM based on the following requirements:\n",
    "\n",
    "    - Use the default tokenizer from sklearn library. \n",
    "    - Remove stop words in the list of nltk. \n",
    "    - Do not stem the terms.\n",
    "    - Create DTM in TFIDF with using bigrams. \n",
    "    - Normalize the rows of DTM so that each row sums up to one. (*Hint: set up norm=\"l1\"*)\n",
    "    \n",
    " Save your DTMs as **train_x** and **train_y**. Print the shape of train_x and train_y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e789735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1334, 71144)\n",
      "(572, 71144)\n"
     ]
    }
   ],
   "source": [
    "#Your answer here:\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "df_train, df_test = train_test_split(df, test_size=0.30, random_state=2021)\n",
    "df_train.reset_index(drop=True,inplace=True)\n",
    "df_test.reset_index(drop=True,inplace=True)\n",
    "\n",
    "nltk_stopwords = nltk.corpus.stopwords.words(\"english\") \n",
    "\n",
    "vectorizer=TfidfVectorizer(stop_words=nltk_stopwords, norm=\"l1\",ngram_range=(2,2))\n",
    "\n",
    "train_x = vectorizer.fit_transform(df_train['Final Narrative'])\n",
    "test_x = vectorizer.transform(df_test[\"Final Narrative\"])\n",
    "\n",
    "#Check your answer\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544eed04",
   "metadata": {},
   "source": [
    "2. Create a sparse logistic regression model with $C=100$ to predict column \"Fatal\" using the DTM matrix created from column \"Final Narrative\". You can set tolerance and max iteration number to any values as long as the warmining message \"failed to converge\" does not show up. Set random_state to 2021 for reproducibility. Save your model as **sparselr**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba08875c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=100, max_iter=1000, penalty=&#x27;l1&#x27;, random_state=2021,\n",
       "                   solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=100, max_iter=1000, penalty=&#x27;l1&#x27;, random_state=2021,\n",
       "                   solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=100, max_iter=1000, penalty='l1', random_state=2021,\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your answer here:\n",
    "train_y = df_train['Fatal']\n",
    "test_y = df_test['Fatal']\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sparselr = LogisticRegression(penalty='l1', \n",
    "                              solver='liblinear',\n",
    "                              random_state=2021,\n",
    "                              tol=0.0001,\n",
    "                              max_iter=1000, \n",
    "                              C=100)\n",
    "sparselr.fit(train_x,train_y)\n",
    "\n",
    "#Check your answer:\n",
    "sparselr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4194cbf",
   "metadata": {},
   "source": [
    "3. Print the number of non-zero betas in **sparselr** from question 2. According to the size of vocabulary shown in question 1, how much percent of betas are non-zero? You can do the calculate manually and type your answer as a comment in the code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "155d83e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n",
      "71144\n",
      "0.0025863038344765546\n"
     ]
    }
   ],
   "source": [
    "#Your answer here:\n",
    "\n",
    "percent = sum(sparselr.coef_[0]!=0) / len(sparselr.coef_[0])\n",
    "print(sum(sparselr.coef_[0]!=0))\n",
    "print(len(sparselr.coef_[0]))\n",
    "print(percent)\n",
    "\n",
    "#how much percent of betas are non-zero? \n",
    "#Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688124d0",
   "metadata": {},
   "source": [
    "4. Print 15 bigrams that have the largest impact to outcome \"Fatal\". \n",
    "\n",
    "*Hint: Which outcome is considered to be the positive class by the model? Non-Fatal or Fatal? Which outcome is considered to be negative by the model? Will you look for positive betas or negative betas? Will you sort betas in ascending or descending order?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1904697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abromeland/.local/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>obtained various</td>\n",
       "      <td>-280.171976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>told pilot</td>\n",
       "      <td>-266.410072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fatally injured</td>\n",
       "      <td>-265.381918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data obtained</td>\n",
       "      <td>-237.870818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>near vertical</td>\n",
       "      <td>-232.141632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fatal injuries</td>\n",
       "      <td>-231.345805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>control continuity</td>\n",
       "      <td>-206.399608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>due loss</td>\n",
       "      <td>-196.969635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>revealed evidence</td>\n",
       "      <td>-196.245399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pilot blood</td>\n",
       "      <td>-180.107276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>observed aircraft</td>\n",
       "      <td>-151.487617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>witness reported</td>\n",
       "      <td>-148.787447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fence pole</td>\n",
       "      <td>-134.015183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>right turn</td>\n",
       "      <td>-131.648091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>witness said</td>\n",
       "      <td>-128.200511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Term        Beta\n",
       "0     obtained various -280.171976\n",
       "1           told pilot -266.410072\n",
       "2      fatally injured -265.381918\n",
       "3        data obtained -237.870818\n",
       "4        near vertical -232.141632\n",
       "5       fatal injuries -231.345805\n",
       "6   control continuity -206.399608\n",
       "7             due loss -196.969635\n",
       "8    revealed evidence -196.245399\n",
       "9          pilot blood -180.107276\n",
       "10   observed aircraft -151.487617\n",
       "11    witness reported -148.787447\n",
       "12          fence pole -134.015183\n",
       "13          right turn -131.648091\n",
       "14        witness said -128.200511"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your answer here:\n",
    "dfbeta = pd.DataFrame({'Term': vectorizer.get_feature_names(),\n",
    "                       'Beta': sparselr.coef_[0]\n",
    "                     })\n",
    "\n",
    "dfbeta.sort_values(by=\"Beta\",inplace=True,ascending=True)\n",
    "dfbeta.reset_index(inplace=True,drop=True)\n",
    "\n",
    "#Check your answer:\n",
    "dfbeta.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b333e6aa",
   "metadata": {},
   "source": [
    "5. Print 15 bigrams that have the largest impact to outcome \"Non-Fatal\".\n",
    "\n",
    "*Hint: Same as question 4*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14288df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pilot performing</td>\n",
       "      <td>331.102885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data provided</td>\n",
       "      <td>299.683184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>may traveled</td>\n",
       "      <td>273.634377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>provided various</td>\n",
       "      <td>262.316015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forced landing</td>\n",
       "      <td>185.639204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>landing gear</td>\n",
       "      <td>175.112586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lost power</td>\n",
       "      <td>133.484921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pattern altitude</td>\n",
       "      <td>129.624603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>selector position</td>\n",
       "      <td>126.844666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>student pilot</td>\n",
       "      <td>106.672004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pilot reported</td>\n",
       "      <td>103.692634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>side runway</td>\n",
       "      <td>96.866950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pilot stated</td>\n",
       "      <td>92.508566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>flight crew</td>\n",
       "      <td>83.670479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pilot said</td>\n",
       "      <td>74.865190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Term        Beta\n",
       "0    pilot performing  331.102885\n",
       "1       data provided  299.683184\n",
       "2        may traveled  273.634377\n",
       "3    provided various  262.316015\n",
       "4      forced landing  185.639204\n",
       "5        landing gear  175.112586\n",
       "6          lost power  133.484921\n",
       "7    pattern altitude  129.624603\n",
       "8   selector position  126.844666\n",
       "9       student pilot  106.672004\n",
       "10     pilot reported  103.692634\n",
       "11        side runway   96.866950\n",
       "12       pilot stated   92.508566\n",
       "13        flight crew   83.670479\n",
       "14         pilot said   74.865190"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your answer here:\n",
    "dfbeta.sort_values(by=\"Beta\",inplace=True,ascending=False)\n",
    "dfbeta.reset_index(inplace=True,drop=True)\n",
    "\n",
    "#Check your answer:\n",
    "dfbeta.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796b0fd2",
   "metadata": {},
   "source": [
    "6. Print the prediction accuracy of **sparselr** on training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "078dbeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "0.9835082458770614\n",
      "Test:\n",
      "0.9423076923076923\n"
     ]
    }
   ],
   "source": [
    "#Your answer here:\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "print(\"Train:\")\n",
    "print(accuracy_score(train_y,sparselr.predict(train_x)))\n",
    "print(\"Test:\")\n",
    "print(accuracy_score(test_y,sparselr.predict(test_x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a68482",
   "metadata": {},
   "source": [
    "7. Print the AUC score of **sparselr** on training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11895a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "0.9992216874718003\n",
      "Test:\n",
      "0.9576149425287356\n"
     ]
    }
   ],
   "source": [
    "#Your answer here:\n",
    "print(\"Train:\")\n",
    "print(roc_auc_score(train_y,sparselr.predict_proba(train_x)[:, 1]))\n",
    "print(\"Test:\")\n",
    "print(roc_auc_score(test_y,sparselr.predict_proba(test_x)[:, 1]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
