{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class Predictive Model | BAIS:6100\n",
    "\n",
    "**Instructor: Qihang Lin**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will study how to apply sparse logistic regression model and XGBoost model to classify documents into one of three or more classes. \n",
    "\n",
    "Similar to the binary case, multi-class classification also consists of three steps: 1. Dataset Preparation; 2. Feature Engineering; 3. Model Training. Since steps 1 and 2 are the same as the binary case, this tutorial will focus on step 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv file \"classdata/foursciences.csv\" contains the posts from a forum. Each post is about one of the four scientific topics, which are cryptography, medicine, space and electronics. You task is to build a predictive model that can predict the topic of a post. \n",
    "\n",
    "- Column \"topic\" contains the class labels (\"crypt\", \"med\", \"space\", or \"electronics\"). \n",
    "- Column \"text\" contains the texts of posts. \n",
    "\n",
    "The following code reads the data and shows the frequencies of the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Archive-name: ripem/faq\\nLast-update: Sun, 7 M...</td>\n",
       "      <td>crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Archive-name: ripem/faq\\nLast-update: 31 Mar 9...</td>\n",
       "      <td>crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Archive-name: ripem/attacks\\nLast-update: 31 M...</td>\n",
       "      <td>crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&gt;&gt;If you have access to FTP, try FTPing to rsa...</td>\n",
       "      <td>crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Some sick part of me really liked that phra...</td>\n",
       "      <td>crypt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  topic\n",
       "0  Archive-name: ripem/faq\\nLast-update: Sun, 7 M...  crypt\n",
       "1  Archive-name: ripem/faq\\nLast-update: 31 Mar 9...  crypt\n",
       "2  Archive-name: ripem/attacks\\nLast-update: 31 M...  crypt\n",
       "3  >>If you have access to FTP, try FTPing to rsa...  crypt\n",
       "4     Some sick part of me really liked that phra...  crypt"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"classdata/foursciences.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crypt          991\n",
       "med            988\n",
       "space          985\n",
       "electronics    984\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"topic\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Class Sparse Logistic Regression: One VS Rest\n",
    "\n",
    "We call the $K$ classses, Class $0$, Class $1$, ..., Class $K-1$. The idea is to build a binary SLR model for each class such that model $0$ predicts if a document is in Class $0$, model $1$ predicts if a document is in Class $1$, so on so forth. This is called **One VS Rest** method.\n",
    "\n",
    "* Vectorization of a document: $\\mathbf{x}=(x_1,x_2,\\dots,x_n)$ \n",
    "    * $\\mathbf{x}$ is a row in DTM and also called a feature vector.\n",
    "    \n",
    "* Each document has a class label, denoted by $y$.\n",
    "    * For example, $y=0,1,\\dots,K-1$ in $K$-class classification.\n",
    "\n",
    "* A linear score is defined for class $0,1,2,\\dots,K-1$ separately: \n",
    "    * Class $0$: $\\alpha^0+\\beta_1^0x_1+\\beta_2^0x_2+\\cdots+\\beta_n^0x_n$\n",
    "    * Class $1$: $\\alpha^1+\\beta_1^1x_1+\\beta_2^1x_2+\\cdots+\\beta_n^1x_n$\n",
    "    * ......\n",
    "    * Class $K-1$: $\\alpha^{K-1}+\\beta_1^{K-1}x_1+\\beta_2^{K-1}x_2+\\cdots+\\beta_n^{K-1}x_n$\n",
    "* Coefficients $k=0,1,\\dots,K-1$: \n",
    "    * Intercept: $\\alpha^k$ \n",
    "    * Slopes: $\\mathbf{\\beta}^k=(\\beta_1^k,\\beta_2^k,\\dots,\\beta_n^k)$\n",
    "* Logistic regression makes prediction based on the linear score:\n",
    "    * Predict $y$ as Class $k$ if the $k$th linear score above is larger than other $K-1$ scores. \n",
    "* Impact of terms: \n",
    "    * $\\beta_i^k>0$: A document with a high frequency in term $i$ will be more likely in Class $k$. \n",
    "    * $\\beta_i^k<0$: A document with a high frequency in term $i$ will be less likely in Class $k$. \n",
    "    * $\\beta_i^k=0$: Term $i$ has no impact on the class label $k$ (but may still have impact on other classes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is the same as binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size=0.30, random_state=2021)\n",
    "df_train.reset_index(drop=True,inplace=True)\n",
    "df_test.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Feature Engineering\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import nltk \n",
    "\n",
    "stemmer = nltk.stem.SnowballStemmer(\"english\")\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedTfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "\n",
    "nltk_stopwords = nltk.corpus.stopwords.words(\"english\") \n",
    "\n",
    "vectorizer=StemmedTfidfVectorizer(stop_words=nltk_stopwords, norm=None)\n",
    "\n",
    "#Create the training and testing DTMs and the labels\n",
    "train_x = vectorizer.fit_transform(df_train[\"text\"])\n",
    "train_y = df_train[\"topic\"]\n",
    "test_x = vectorizer.transform(df_test[\"text\"])\n",
    "test_y = df_test[\"topic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Multi-Class SLR Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference in this step from the binary case is to set argument **multi_class='ovr'**. Here **ovr** means \"one vs rest\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, max_iter=1000, multi_class='ovr', penalty='l1',\n",
       "                   random_state=2021, solver='liblinear', tol=0.01)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model training\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "sparselr = LogisticRegression(penalty='l1', \n",
    "                              solver='liblinear',\n",
    "                              multi_class='ovr', ##Remember to set this for multi-class case\n",
    "                              random_state=2021,\n",
    "                              tol=0.01,\n",
    "                              max_iter=1000, \n",
    "                              C=1)\n",
    "sparselr.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sklearn** library converts the original text class labels into Class $0$, Class $1$, ... and Class $K-1$ by alphabetical rule. In this example, \n",
    "   * 'crypt' is Class $0$\n",
    "   * 'electronics' is Class $1$\n",
    "   * 'med' is Class $2$\n",
    "   * 'space' is Class $3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four slope coefficients $\\beta_i^k$ for each term, representing its impact to each of the four classes. Hence,  slope coefficients $\\beta_i^k$ should be a 2D table. See its shape below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 29655)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape of slope coefficient matrix. Each row is a class and each column is a term.\n",
    "sparselr.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.00828141 0.         ... 0.         0.         0.        ]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[ 0.         -0.03782684  0.         ...  0.          0.\n",
      "  0.        ]\n",
      "[0.         0.03240413 0.         ... 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "#Slope betas for class 0, 1, 2 and 3.\n",
    "print(sparselr.coef_[0])  #Slope of each term for class 0\n",
    "print(sparselr.coef_[1])  #Slope of each term for class 1  \n",
    "print(sparselr.coef_[2])  #Slope of each term for class 2\n",
    "print(sparselr.coef_[3])  #Slope of each term for class 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.5382228430655507\n",
      "-1.018189090055603\n",
      "-1.129507609889858\n",
      "-1.2260173351099795\n"
     ]
    }
   ],
   "source": [
    "#Intercept alpha for class 0, 1, 2 and 3.\n",
    "print(sparselr.intercept_[0])  #Intercept for class 0\n",
    "print(sparselr.intercept_[1])  #Intercept for class 1\n",
    "print(sparselr.intercept_[2])  #Intercept for class 2\n",
    "print(sparselr.intercept_[3])  #Intercept for class 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1394\n",
      "1641\n",
      "1554\n",
      "1501\n"
     ]
    }
   ],
   "source": [
    "#How many non-zero betas in total (Sparsity). There are 30000s terms.\n",
    "print(sum(sparselr.coef_[0]!=0))\n",
    "print(sum(sparselr.coef_[1]!=0))\n",
    "print(sum(sparselr.coef_[2]!=0))\n",
    "print(sum(sparselr.coef_[3]!=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can identify the terms that have the largest impacts to class $k$ by sorting $\\beta_0^k$, $\\beta_1^k$, $\\beta_2^k$, ...,$\\beta_n^k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a table with term and its four sequences of beta (one sequence for each class)\n",
    "dfbeta = pd.DataFrame({'Term': vectorizer.get_feature_names(),\n",
    "                       'Beta0': sparselr.coef_[0],\n",
    "                       'Beta1': sparselr.coef_[1],\n",
    "                       'Beta2': sparselr.coef_[2],\n",
    "                       'Beta3': sparselr.coef_[3]\n",
    "                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Beta0</th>\n",
       "      <th>Beta1</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Beta3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mathew</td>\n",
       "      <td>0.478685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.109287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crypt</td>\n",
       "      <td>0.454312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.068029</td>\n",
       "      <td>-0.014402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>omiss</td>\n",
       "      <td>0.452885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>forbidden</td>\n",
       "      <td>0.436091</td>\n",
       "      <td>-0.124673</td>\n",
       "      <td>-0.156081</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>decript</td>\n",
       "      <td>0.397477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kelsey</td>\n",
       "      <td>0.367561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rdl</td>\n",
       "      <td>0.351950</td>\n",
       "      <td>-0.147157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>occam</td>\n",
       "      <td>0.330310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.110946</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>substitut</td>\n",
       "      <td>0.321596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hermann</td>\n",
       "      <td>0.316392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Term     Beta0     Beta1     Beta2     Beta3\n",
       "0     mathew  0.478685  0.000000  0.000000 -0.109287\n",
       "1      crypt  0.454312  0.000000 -0.068029 -0.014402\n",
       "2      omiss  0.452885  0.000000  0.000000  0.000000\n",
       "3  forbidden  0.436091 -0.124673 -0.156081  0.000000\n",
       "4    decript  0.397477  0.000000  0.000000  0.000000\n",
       "5     kelsey  0.367561  0.000000  0.000000  0.000000\n",
       "6        rdl  0.351950 -0.147157  0.000000  0.000000\n",
       "7      occam  0.330310  0.000000 -0.110946  0.000000\n",
       "8  substitut  0.321596  0.000000  0.000000  0.000000\n",
       "9    hermann  0.316392  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the terms that have the largest impact to Class 0 (in a descending order).\n",
    "dfbeta.sort_values(by=\"Beta0\",inplace=True,ascending=False)\n",
    "dfbeta.reset_index(inplace=True,drop=True)\n",
    "dfbeta.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Beta0</th>\n",
       "      <th>Beta1</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Beta3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yxy4145</td>\n",
       "      <td>-0.001464</td>\n",
       "      <td>0.505077</td>\n",
       "      <td>-0.069072</td>\n",
       "      <td>-0.125707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>solvent</td>\n",
       "      <td>-0.127805</td>\n",
       "      <td>0.434965</td>\n",
       "      <td>-0.172994</td>\n",
       "      <td>-0.226376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nikolai</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.410533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>motorola</td>\n",
       "      <td>-0.141929</td>\n",
       "      <td>0.392147</td>\n",
       "      <td>-0.204707</td>\n",
       "      <td>-0.222962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aftershav</td>\n",
       "      <td>-0.047610</td>\n",
       "      <td>0.380306</td>\n",
       "      <td>-0.043176</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dayton</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376375</td>\n",
       "      <td>-0.052481</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hd</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369702</td>\n",
       "      <td>-0.030905</td>\n",
       "      <td>-0.071864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gandler</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356764</td>\n",
       "      <td>-0.077681</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>schemat</td>\n",
       "      <td>-0.032308</td>\n",
       "      <td>0.333382</td>\n",
       "      <td>-0.038664</td>\n",
       "      <td>-0.027997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cci</td>\n",
       "      <td>-0.021818</td>\n",
       "      <td>0.330066</td>\n",
       "      <td>-0.069711</td>\n",
       "      <td>-0.069345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Term     Beta0     Beta1     Beta2     Beta3\n",
       "0    yxy4145 -0.001464  0.505077 -0.069072 -0.125707\n",
       "1    solvent -0.127805  0.434965 -0.172994 -0.226376\n",
       "2    nikolai  0.000000  0.410533  0.000000 -0.004542\n",
       "3   motorola -0.141929  0.392147 -0.204707 -0.222962\n",
       "4  aftershav -0.047610  0.380306 -0.043176  0.000000\n",
       "5     dayton  0.000000  0.376375 -0.052481  0.000000\n",
       "6         hd  0.000000  0.369702 -0.030905 -0.071864\n",
       "7    gandler  0.000000  0.356764 -0.077681  0.000000\n",
       "8    schemat -0.032308  0.333382 -0.038664 -0.027997\n",
       "9        cci -0.021818  0.330066 -0.069711 -0.069345"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the terms that have the largest impact to Class 1 (in a descending order).\n",
    "dfbeta.sort_values(by=\"Beta1\",inplace=True,ascending=False)\n",
    "dfbeta.reset_index(inplace=True,drop=True)\n",
    "dfbeta.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Beta0</th>\n",
       "      <th>Beta1</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Beta3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vs</td>\n",
       "      <td>-0.075435</td>\n",
       "      <td>-0.049148</td>\n",
       "      <td>0.434462</td>\n",
       "      <td>-0.056806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ecg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.082585</td>\n",
       "      <td>0.390758</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>morphin</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006892</td>\n",
       "      <td>0.387095</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>med</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.196239</td>\n",
       "      <td>0.371658</td>\n",
       "      <td>-0.129886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>osteopathi</td>\n",
       "      <td>-0.051365</td>\n",
       "      <td>-0.100121</td>\n",
       "      <td>0.370791</td>\n",
       "      <td>-0.087062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>diagnos</td>\n",
       "      <td>-0.051815</td>\n",
       "      <td>-0.102983</td>\n",
       "      <td>0.342373</td>\n",
       "      <td>-0.026415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>girli</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327651</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>eyelid</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315495</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pathophysiolog</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.127093</td>\n",
       "      <td>0.309430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>diverticular</td>\n",
       "      <td>-0.056903</td>\n",
       "      <td>-0.035239</td>\n",
       "      <td>0.306203</td>\n",
       "      <td>-0.034024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Term     Beta0     Beta1     Beta2     Beta3\n",
       "0              vs -0.075435 -0.049148  0.434462 -0.056806\n",
       "1             ecg  0.000000 -0.082585  0.390758  0.000000\n",
       "2         morphin  0.000000 -0.006892  0.387095  0.000000\n",
       "3             med  0.000000 -0.196239  0.371658 -0.129886\n",
       "4      osteopathi -0.051365 -0.100121  0.370791 -0.087062\n",
       "5         diagnos -0.051815 -0.102983  0.342373 -0.026415\n",
       "6           girli  0.000000  0.000000  0.327651  0.000000\n",
       "7          eyelid  0.000000  0.000000  0.315495  0.000000\n",
       "8  pathophysiolog  0.000000 -0.127093  0.309430  0.000000\n",
       "9    diverticular -0.056903 -0.035239  0.306203 -0.034024"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the terms that have the largest impact to Class 2 (in a descending order).\n",
    "dfbeta.sort_values(by=\"Beta2\",inplace=True,ascending=False)\n",
    "dfbeta.reset_index(inplace=True,drop=True)\n",
    "dfbeta.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Beta0</th>\n",
       "      <th>Beta1</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Beta3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jennis</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.148584</td>\n",
       "      <td>-0.067012</td>\n",
       "      <td>0.691701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wallop</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.018720</td>\n",
       "      <td>0.402537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>freebairn</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.123640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.391155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>troop</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.104550</td>\n",
       "      <td>-0.071294</td>\n",
       "      <td>0.385970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nicol</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pat</td>\n",
       "      <td>-0.192517</td>\n",
       "      <td>-0.247104</td>\n",
       "      <td>-0.265129</td>\n",
       "      <td>0.332954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>missil</td>\n",
       "      <td>-0.012079</td>\n",
       "      <td>-0.058853</td>\n",
       "      <td>-0.022674</td>\n",
       "      <td>0.321594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tdrs</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.320883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>astro</td>\n",
       "      <td>-0.031615</td>\n",
       "      <td>-0.098924</td>\n",
       "      <td>-0.160845</td>\n",
       "      <td>0.310421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>adam</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.084369</td>\n",
       "      <td>-0.135387</td>\n",
       "      <td>0.292048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Term     Beta0     Beta1     Beta2     Beta3\n",
       "0     jennis  0.000000 -0.148584 -0.067012  0.691701\n",
       "1     wallop  0.000000  0.000000 -0.018720  0.402537\n",
       "2  freebairn  0.000000 -0.123640  0.000000  0.391155\n",
       "3      troop  0.000000 -0.104550 -0.071294  0.385970\n",
       "4      nicol  0.000000  0.000000  0.000000  0.333689\n",
       "5        pat -0.192517 -0.247104 -0.265129  0.332954\n",
       "6     missil -0.012079 -0.058853 -0.022674  0.321594\n",
       "7       tdrs  0.000000  0.000000  0.000000  0.320883\n",
       "8      astro -0.031615 -0.098924 -0.160845  0.310421\n",
       "9       adam  0.000000 -0.084369 -0.135387  0.292048"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the terms that have the largest impact to Class 3 (in a descending order).\n",
    "dfbeta.sort_values(by=\"Beta3\",inplace=True,ascending=False)\n",
    "dfbeta.reset_index(inplace=True,drop=True)\n",
    "dfbeta.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is also similar to binary case except that there are four predicted probabilities instead of two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['med', 'electronics', 'space', 'electronics', 'crypt',\n",
       "       'electronics', 'electronics', 'electronics', 'crypt', 'med'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply the model to the testing set and predict the class labels\n",
    "sparselr.predict(test_x)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.69325153e-03, 4.44243027e-02, 9.38697803e-01, 1.51846429e-02],\n",
       "       [6.16509219e-04, 9.95105465e-01, 8.40622155e-04, 3.43740329e-03],\n",
       "       [2.72096500e-04, 9.20785674e-06, 7.18886624e-03, 9.92529829e-01],\n",
       "       [5.50055022e-04, 9.97643472e-01, 1.40164243e-03, 4.04831000e-04],\n",
       "       [9.55059579e-01, 2.98753415e-02, 9.63979128e-03, 5.42528805e-03],\n",
       "       [1.17472274e-01, 5.28819865e-01, 2.56899361e-01, 9.68084996e-02],\n",
       "       [1.08514438e-03, 9.80360385e-01, 1.32242090e-02, 5.33026128e-03],\n",
       "       [5.38177645e-03, 8.75056110e-01, 1.07040148e-01, 1.25219657e-02],\n",
       "       [9.98008426e-01, 1.33859357e-03, 2.30822650e-04, 4.22158253e-04],\n",
       "       [9.85681588e-04, 3.36680505e-03, 9.42891313e-01, 5.27562001e-02]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the probability of each doc being in each class \n",
    "#The columns correspond to 'crypt', 'electronics', 'med' and 'space' (in alphabetical order)\n",
    "sparselr.predict_proba(test_x)[0:10]  #Here, 0:10 means showing the results for only 10 documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metric\n",
    "\n",
    "**Confusion table**: In the example below, there are 10, 2, 2 and 2 instances from the true Class0 are predicted as Class0, Class1, Class2 and Class3, respectively. Other rows should be understood in a similar way.\n",
    "\n",
    "| | Pred Class0 | Pred Class1 | Pred Class2 | Pred Class3 |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| True Class0 | 10 | 2 | 2 | 2 |\n",
    "| True Class1 | 2 | 10 | 2 | 2 |\n",
    "| True Class2 | 2 | 2 | 10 | 2 |\n",
    "| True Class3 | 2 | 2 | 2 | 10 |\n",
    "\n",
    "**Accuracy**: The percentage of correct predictions made by a model. \n",
    "\n",
    "- With the confusion table above, accuracy=$\\frac{10+10+10+10}{10+10+10+10+2\\times12}=\\%76.9$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix:\n",
      "[[692   0   0   0]\n",
      " [  0 669   0   0]\n",
      " [  0   0 701   0]\n",
      " [  0   0   1 700]]\n",
      "Test Confusion Matrix:\n",
      "[[278  12   1   8]\n",
      " [  4 299   5   7]\n",
      " [  3  10 273   1]\n",
      " [  1   8   6 269]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Train Confusion Matrix:\")\n",
    "print(confusion_matrix(train_y, sparselr.predict(train_x)))\n",
    "print(\"Test Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, sparselr.predict(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:\n",
      "0.9996380745566413\n",
      "Test Accuracy:\n",
      "0.9443037974683545\n"
     ]
    }
   ],
   "source": [
    "#Performance evaluation in terms of accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Train Accuracy:\")\n",
    "print(accuracy_score(train_y,sparselr.predict(train_x)))\n",
    "print(\"Test Accuracy:\")\n",
    "print(accuracy_score(test_y,sparselr.predict(test_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multi-class classificaiton, **multi_class=\"ovr\"** should be set in order to calculate AUC scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:\n",
      "0.9999996540898342\n",
      "Test Accuracy:\n",
      "0.9919739991643397\n"
     ]
    }
   ],
   "source": [
    "#Performance evaluation in terms of AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"Train Accuracy:\")\n",
    "print(roc_auc_score(train_y,sparselr.predict_proba(train_x), multi_class=\"ovr\"))\n",
    "print(\"Test Accuracy:\")\n",
    "print(roc_auc_score(test_y,sparselr.predict_proba(test_x), multi_class=\"ovr\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation for Multi-Class SLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for the optimal $C$ can be done with cross validation. The code is exactly the same as the binary case except that **multi_class='ovr'**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.60364177e-04, 8.43838656e-04, 1.54673998e-03, 2.83514455e-03,\n",
       "       5.19676527e-03, 9.52557049e-03, 1.74601870e-02, 3.20041859e-02,\n",
       "       5.86630555e-02, 1.07528249e-01, 1.97097206e-01, 3.61275378e-01,\n",
       "       6.62210798e-01, 1.21381962e+00, 2.22490795e+00, 4.07821336e+00,\n",
       "       7.47528641e+00, 1.37020558e+01, 2.51156040e+01, 4.60364177e+01])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate the grid of parameters that increase proportionally.\n",
    "import numpy as np\n",
    "from sklearn.svm import l1_min_c\n",
    "param_grid = l1_min_c(train_x, train_y, loss='log') * np.logspace(start=0, stop=5, num=20) \n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=array([4.60364177e-04, 8.43838656e-04, 1.54673998e-03, 2.83514455e-03,\n",
       "       5.19676527e-03, 9.52557049e-03, 1.74601870e-02, 3.20041859e-02,\n",
       "       5.86630555e-02, 1.07528249e-01, 1.97097206e-01, 3.61275378e-01,\n",
       "       6.62210798e-01, 1.21381962e+00, 2.22490795e+00, 4.07821336e+00,\n",
       "       7.47528641e+00, 1.37020558e+01, 2.51156040e+01, 4.60364177e+01]),\n",
       "                     cv=5, max_iter=1000, multi_class='ovr', penalty='l1',\n",
       "                     random_state=2021, scoring='accuracy', solver='liblinear',\n",
       "                     tol=0.01)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "sparselr = LogisticRegressionCV(penalty='l1', \n",
    "                                solver='liblinear', \n",
    "                                Cs=param_grid,   #Use the grid generated above\n",
    "                                cv=5,            #Number of folds, that is, K\n",
    "                                scoring='accuracy', #The performance metric to select the best C.\n",
    "                                multi_class='ovr', \n",
    "                                random_state=2021,  #To make sure the result is reproducible\n",
    "                                tol=0.01,\n",
    "                                max_iter=1000)\n",
    "sparselr.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use AUC as the performance metric, set **scoring='roc_auc'** above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:\n",
      "0.9996380745566413\n",
      "Test Accuracy:\n",
      "0.950210970464135\n"
     ]
    }
   ],
   "source": [
    "#Performance evaluation in terms of accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Train Accuracy:\")\n",
    "print(accuracy_score(train_y,sparselr.predict(train_x)))\n",
    "print(\"Test Accuracy:\")\n",
    "print(accuracy_score(test_y,sparselr.predict(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:\n",
      "0.9999996540898344\n",
      "Test Accuracy:\n",
      "0.9931027019401462\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"Train Accuracy:\")\n",
    "print(roc_auc_score(train_y,sparselr.predict_proba(train_x), multi_class=\"ovr\"))\n",
    "print(\"Test Accuracy:\")\n",
    "print(roc_auc_score(test_y,sparselr.predict_proba(test_x), multi_class=\"ovr\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Class XGBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The codes for building a multi-class XGBoost is **exactly the same** as the binary case except that the text class labels should be first encoded into 0, 1, 2, 3 following an alphabetical order. See **preprocessing.LabelEncoder()** below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a XGB model\n",
    "xgb=XGBClassifier(n_estimators=200,    #How many trees in total\n",
    "                  max_depth=5,         #The depth of each tree\n",
    "                  nthread=4,           #Multi-thread speed up\n",
    "                  use_label_encoder=False,  #To avoid an unimportant warning message \n",
    "                  verbosity = 0,       #Hidden other messages during training\n",
    "                  random_state=2021)   #Fix the results of random sampling during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBClassifier** requires numeric class labels so we need to encode the labels first. By default, \n",
    "they will be encoded by the alphabetically order. In this case, 0=crypt, 1=electronics, 2=med, 3=space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1, ..., 2, 3, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encode the text lables in to 0, 1, 2,...\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "train_y=le.fit_transform(train_y)\n",
    "test_y=le.transform(test_y)\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=200,\n",
       "              n_jobs=4, nthread=4, num_parallel_tree=1,\n",
       "              objective='multi:softprob', predictor='auto', random_state=2021, ...)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Analytics (XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosting calculates an importance score for each term that indicates how useful that term was in the construction of the decision trees within the model.\n",
    "\n",
    "The more useful a term is in making a prediction, the higher its importance is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medic</td>\n",
       "      <td>0.023729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amp</td>\n",
       "      <td>0.020726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>encrypt</td>\n",
       "      <td>0.018355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clipper</td>\n",
       "      <td>0.018019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>circuit</td>\n",
       "      <td>0.016998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gordon</td>\n",
       "      <td>0.015490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>space</td>\n",
       "      <td>0.012574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>key</td>\n",
       "      <td>0.011997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>doctor</td>\n",
       "      <td>0.011246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>treatment</td>\n",
       "      <td>0.010725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Term  Importance\n",
       "0      medic    0.023729\n",
       "1        amp    0.020726\n",
       "2    encrypt    0.018355\n",
       "3    clipper    0.018019\n",
       "4    circuit    0.016998\n",
       "5     gordon    0.015490\n",
       "6      space    0.012574\n",
       "7        key    0.011997\n",
       "8     doctor    0.011246\n",
       "9  treatment    0.010725"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfbeta = pd.DataFrame({'Term': vectorizer.get_feature_names(),\n",
    "                       'Importance': xgb.feature_importances_\n",
    "                     })\n",
    "dfbeta.sort_values(by=\"Importance\",inplace=True,ascending=False)\n",
    "dfbeta.reset_index(inplace=True,drop=True)\n",
    "dfbeta.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Analytics  (XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions by XGBoost are implemented in a way similar to SLR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, 1, 0, 2, 1, 1, 0, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply the model to the reviews testing set and predict the classes (encoded into 0, 1, 2, 3)\n",
    "xgb.predict(test_x)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.8628282e-03, 3.6727185e-03, 9.8960155e-01, 4.8629339e-03],\n",
       "       [2.5772478e-03, 9.7599483e-01, 1.6008351e-02, 5.4195407e-03],\n",
       "       [1.1951150e-03, 3.1492312e-04, 2.4162915e-03, 9.9607372e-01],\n",
       "       [2.0617708e-05, 9.9991596e-01, 1.7888802e-05, 4.5530174e-05],\n",
       "       [9.9874842e-01, 9.3018153e-04, 2.2312807e-04, 9.8274104e-05],\n",
       "       [6.5765195e-02, 4.0896973e-01, 4.4393978e-01, 8.1325270e-02],\n",
       "       [1.5990302e-03, 9.8985171e-01, 4.8631728e-03, 3.6861652e-03],\n",
       "       [5.8021598e-02, 7.4757516e-01, 1.4469145e-01, 4.9711838e-02],\n",
       "       [9.9981886e-01, 4.0889270e-05, 1.1698996e-05, 1.2859701e-04],\n",
       "       [1.0361956e-05, 2.0908603e-05, 9.9993110e-01, 3.7624468e-05]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the probability in each class (in alphabetical order of the classes)\n",
    "xgb.predict_proba(test_x)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:\n",
      "0.9996380745566413\n",
      "Test Accuracy:\n",
      "0.9308016877637131\n",
      "Train AUC:\n",
      "0.9999996540898343\n",
      "Test AUC:\n",
      "0.9914291374755656\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy:\")\n",
    "print(accuracy_score(train_y,xgb.predict(train_x)))\n",
    "print(\"Test Accuracy:\")\n",
    "print(accuracy_score(test_y,xgb.predict(test_x)))\n",
    "print(\"Train AUC:\")\n",
    "print(roc_auc_score(train_y,xgb.predict_proba(train_x), multi_class=\"ovr\"))\n",
    "print(\"Test AUC:\")\n",
    "print(roc_auc_score(test_y,xgb.predict_proba(test_x), multi_class=\"ovr\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation (XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation for XGBoost can be done in the same way as in the binary case. The codes may take about 30 seconds. Please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=2021, reg_alpha=None, ...),\n",
       "             param_grid={'max_depth': [2, 5], 'n_estimators': [10, 100]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV   \n",
    "param_list = {  \n",
    " 'max_depth':[2, 5],       #Candidate for max_depth\n",
    " 'n_estimators':[10, 100]  #Candidate for n_estimators\n",
    "}\n",
    "xgb=XGBClassifier(nthread=4,\n",
    "                  use_label_encoder=False,\n",
    "                  verbosity = 0,\n",
    "                  random_state=2021\n",
    "                 )\n",
    "xgb = GridSearchCV(estimator = xgb, \n",
    "                   param_grid = param_list,\n",
    "                   scoring = 'accuracy',  #The performance metric to select the best parameters.\n",
    "                   cv=5                   #Number of folds, i.e., K\n",
    "                  )  \n",
    "xgb.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'n_estimators': 100}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the best combination of parameters.\n",
    "xgb.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance using the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix:\n",
      "[[691   0   1   0]\n",
      " [  0 667   2   0]\n",
      " [  0   1 700   0]\n",
      " [  0   0   2 699]]\n",
      "Test Confusion Matrix:\n",
      "[[279  14   4   2]\n",
      " [  4 288  15   8]\n",
      " [  1   9 271   6]\n",
      " [  2   7  11 264]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Train Confusion Matrix:\")\n",
    "print(confusion_matrix(train_y, xgb.predict(train_x)))\n",
    "print(\"Test Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, xgb.predict(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:\n",
      "0.997828447339848\n",
      "Test Accuracy:\n",
      "0.929957805907173\n",
      "Train AUC:\n",
      "0.9999924829076889\n",
      "Test AUC:\n",
      "0.9914886153602305\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy:\")\n",
    "print(accuracy_score(train_y,xgb.predict(train_x)))\n",
    "print(\"Test Accuracy:\")\n",
    "print(accuracy_score(test_y,xgb.predict(test_x)))\n",
    "print(\"Train AUC:\")\n",
    "print(roc_auc_score(train_y,xgb.predict_proba(train_x), multi_class=\"ovr\"))\n",
    "print(\"Test AUC:\")\n",
    "print(roc_auc_score(test_y,xgb.predict_proba(test_x), multi_class=\"ovr\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
