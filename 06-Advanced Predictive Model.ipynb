{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a078b11c",
   "metadata": {},
   "source": [
    "# Advanced Predictive Model | BAIS:6100\n",
    "\n",
    "**Instructor: Qihang Lin**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b508cde",
   "metadata": {},
   "source": [
    "## Sparse Linear Model -- A Quick Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2283033c",
   "metadata": {},
   "source": [
    "A spare linear model with a given $C$ can be trained and tested as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f343fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data for this example\n",
    "import pandas as pd\n",
    "import re\n",
    "df = pd.read_csv(\"classdata/Lies_and_Truths.csv\")\n",
    "df = df[df.Domain==\"Electronics\"].copy()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df = df[[\"Sentiment Polarity\",\"Review\"]]   #Keep only the columns we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "861c05bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size=0.33, random_state=2021)\n",
    "df_train.reset_index(drop=True,inplace=True)\n",
    "df_test.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a889da4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import nltk \n",
    "\n",
    "stemmer = nltk.stem.SnowballStemmer(\"english\")\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedTfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "\n",
    "nltk_stopwords = nltk.corpus.stopwords.words(\"english\") \n",
    "\n",
    "vectorizer=StemmedTfidfVectorizer(stop_words=nltk_stopwords, norm=None)\n",
    "\n",
    "#Create the training and testing DTMs and the labels\n",
    "train_x = vectorizer.fit_transform(df_train[\"Review\"])\n",
    "train_y = df_train[\"Sentiment Polarity\"]\n",
    "test_x = vectorizer.transform(df_test[\"Review\"])\n",
    "test_y = df_test[\"Sentiment Polarity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d9e6729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, max_iter=1000, penalty=&#x27;l1&#x27;, random_state=2021,\n",
       "                   solver=&#x27;liblinear&#x27;, tol=0.001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, max_iter=1000, penalty=&#x27;l1&#x27;, random_state=2021,\n",
       "                   solver=&#x27;liblinear&#x27;, tol=0.001)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, max_iter=1000, penalty='l1', random_state=2021,\n",
       "                   solver='liblinear', tol=0.001)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model training\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "sparselr = LogisticRegression(penalty='l1', \n",
    "                              solver='liblinear',\n",
    "                              random_state=2021,\n",
    "                              tol=0.001,\n",
    "                              max_iter=1000, \n",
    "                              C=1)\n",
    "sparselr.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0c57ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many non-zero betas in total (Sparsity)\n",
    "sum(sparselr.coef_[0]!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fcdc5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:\n",
      "0.998109640831758\n",
      "Test Accuracy:\n",
      "0.8352490421455939\n",
      "Train AUC:\n",
      "0.9999928473334859\n",
      "Test AUC:\n",
      "0.9159688642528601\n"
     ]
    }
   ],
   "source": [
    "#Performance evaluation\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "print(\"Train Accuracy:\")\n",
    "print(accuracy_score(train_y,sparselr.predict(train_x)))\n",
    "print(\"Test Accuracy:\")\n",
    "print(accuracy_score(test_y,sparselr.predict(test_x)))\n",
    "print(\"Train AUC:\")\n",
    "print(roc_auc_score(train_y,sparselr.predict_proba(train_x)[:, 1]))\n",
    "print(\"Test AUC:\")\n",
    "print(roc_auc_score(test_y,sparselr.predict_proba(test_x)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894a4cff",
   "metadata": {},
   "source": [
    "Change $C$ to 100000 and to $0.0001$ and run the codes above. How does the sparsity level change? How does the performance change?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b288e6",
   "metadata": {},
   "source": [
    "## What Affect a Model's Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b64c0f",
   "metadata": {},
   "source": [
    "The performance of a predictive model depends on \n",
    "\n",
    "* The hyper-parameter, for example, $C$. \n",
    "* How the DTM is constructed (feature engineering). \n",
    "* solver, tol and max_iter. \n",
    "\n",
    "To improve the performance, we need to carefully tune the hyper-parameters and try different DTMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d05b7d",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd78215",
   "metadata": {},
   "source": [
    "In practice, the regularization parameter $C$ can be tuned using **$K$-fold cross validation** (typically $K=5$). This technique can be used to select any hyper-parameter in any model. \n",
    "\n",
    "<img src=http://ethen8181.github.io/machine-learning/model_selection/img/kfolds.png width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2337104c",
   "metadata": {},
   "source": [
    "1. Generate a list of candidate values for $C$\n",
    "\n",
    "\n",
    "2. For each candidate, do the following:\n",
    "\n",
    "    - Split the training dataset into $K$ groups\n",
    "    - For each unique group:\n",
    "\n",
    "        1. Take the group as a validation set\n",
    "        2. Take the remaining groups as a training set\n",
    "        3. Fit a model on the training set and evaluate it on the validation set\n",
    "        4. Retain the performance score and discard the model\n",
    "\n",
    "    - Summarize the model's performance using the average of $K$ performance scores.\n",
    "\n",
    "\n",
    "3. Repeat this procedure for each candidate value of $C$ and select the value with the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7ae175",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88a3357",
   "metadata": {},
   "source": [
    "Searching for the optimal $C$ precisely is very hard. In reality, depending on the runtime, we can only try around 5~30 different candidates, called **a grid of parameters**. \n",
    "\n",
    "Unless we have a good estimation of the range of $C$, the common practice is to create a grid covering numbers in different scales, for example, 1, 10, 100, 1000. This can be done by generating the candidates that increase proportionally instead of additively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de17d443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.13795364e-03, 1.30837313e-02, 2.39822272e-02, 4.39589598e-02,\n",
       "       8.05759254e-02, 1.47694117e-01, 2.70720468e-01, 4.96225395e-01,\n",
       "       9.09571578e-01, 1.66722716e+00, 3.05599522e+00, 5.60158029e+00,\n",
       "       1.02675886e+01, 1.88202919e+01, 3.44972320e+01, 6.32327608e+01,\n",
       "       1.15904431e+02, 2.12450586e+02, 3.89417826e+02, 7.13795364e+02])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate the grid of parameters that increase proportionally.\n",
    "import numpy as np\n",
    "from sklearn.svm import l1_min_c\n",
    "param_grid = l1_min_c(train_x, train_y, loss='log') * np.logspace(start=0, stop=5, num=20) \n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75263579",
   "metadata": {},
   "source": [
    "*   **l1_min_c** finds the smallest $C$ that makes the model \"empty\", i.e., all $\\beta$'s become zero. Any $C$ smaller than **l1_min_c** will not be interesting.\n",
    "\n",
    "*  **np.logspace(start=0, stop=5, num=20)**  generates 20 numbers that increase proportionally from $10^{0}=1$ to $10^{5}$. They are multiplied to **l1_min_c** to proportionally increase $C$ from **l1_min_c** to **l1_min_c$\\times 10^{5}$**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9d38bd",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c39cdba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegressionCV(Cs=array([7.13795364e-03, 1.30837313e-02, 2.39822272e-02, 4.39589598e-02,\n",
       "       8.05759254e-02, 1.47694117e-01, 2.70720468e-01, 4.96225395e-01,\n",
       "       9.09571578e-01, 1.66722716e+00, 3.05599522e+00, 5.60158029e+00,\n",
       "       1.02675886e+01, 1.88202919e+01, 3.44972320e+01, 6.32327608e+01,\n",
       "       1.15904431e+02, 2.12450586e+02, 3.89417826e+02, 7.13795364e+02]),\n",
       "                     cv=5, max_iter=1000, penalty=&#x27;l1&#x27;, random_state=2021,\n",
       "                     scoring=&#x27;accuracy&#x27;, solver=&#x27;liblinear&#x27;, tol=0.001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionCV</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionCV(Cs=array([7.13795364e-03, 1.30837313e-02, 2.39822272e-02, 4.39589598e-02,\n",
       "       8.05759254e-02, 1.47694117e-01, 2.70720468e-01, 4.96225395e-01,\n",
       "       9.09571578e-01, 1.66722716e+00, 3.05599522e+00, 5.60158029e+00,\n",
       "       1.02675886e+01, 1.88202919e+01, 3.44972320e+01, 6.32327608e+01,\n",
       "       1.15904431e+02, 2.12450586e+02, 3.89417826e+02, 7.13795364e+02]),\n",
       "                     cv=5, max_iter=1000, penalty=&#x27;l1&#x27;, random_state=2021,\n",
       "                     scoring=&#x27;accuracy&#x27;, solver=&#x27;liblinear&#x27;, tol=0.001)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegressionCV(Cs=array([7.13795364e-03, 1.30837313e-02, 2.39822272e-02, 4.39589598e-02,\n",
       "       8.05759254e-02, 1.47694117e-01, 2.70720468e-01, 4.96225395e-01,\n",
       "       9.09571578e-01, 1.66722716e+00, 3.05599522e+00, 5.60158029e+00,\n",
       "       1.02675886e+01, 1.88202919e+01, 3.44972320e+01, 6.32327608e+01,\n",
       "       1.15904431e+02, 2.12450586e+02, 3.89417826e+02, 7.13795364e+02]),\n",
       "                     cv=5, max_iter=1000, penalty='l1', random_state=2021,\n",
       "                     scoring='accuracy', solver='liblinear', tol=0.001)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "sparselr = LogisticRegressionCV(penalty='l1', \n",
    "                                solver='liblinear', \n",
    "                                Cs=param_grid,   #Use the grid generated above\n",
    "                                cv=5,            #Number of folds, that is, K\n",
    "                                scoring='accuracy', #The performance metric to select the best C.\n",
    "                                random_state=2021,  #To make sure the result is reproducible\n",
    "                                tol=0.001,\n",
    "                                max_iter=1000)\n",
    "sparselr.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30df929",
   "metadata": {},
   "source": [
    "To use AUC as the performance metric, set **scoring='roc_auc'**\n",
    "\n",
    "More performance metrics: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "More options: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050353f7",
   "metadata": {},
   "source": [
    "Searching in a large grid needs a long runtime. To speed up, we may have to reduce **stop** or **num** in **np.logspace** or reduce **cv**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00d3e02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.13795364e-03, 1.30837313e-02, 2.39822272e-02, 4.39589598e-02,\n",
       "       8.05759254e-02, 1.47694117e-01, 2.70720468e-01, 4.96225395e-01,\n",
       "       9.09571578e-01, 1.66722716e+00, 3.05599522e+00, 5.60158029e+00,\n",
       "       1.02675886e+01, 1.88202919e+01, 3.44972320e+01, 6.32327608e+01,\n",
       "       1.15904431e+02, 2.12450586e+02, 3.89417826e+02, 7.13795364e+02])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All candicates\n",
    "sparselr.Cs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fc15dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34.497232])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the best value of C among the candidates.\n",
    "sparselr.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fb07db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.518868</td>\n",
       "      <td>0.650943</td>\n",
       "      <td>0.783019</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>0.801887</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.783019</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.745283</td>\n",
       "      <td>0.754717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.518868</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.783019</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.877358</td>\n",
       "      <td>0.877358</td>\n",
       "      <td>0.858491</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.877358</td>\n",
       "      <td>0.877358</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>0.764151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.509434</td>\n",
       "      <td>0.650943</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.801887</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.688679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.509434</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.801887</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.830189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.838095</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.518868  0.650943  0.783019  0.820755  0.801887  0.792453  0.783019   \n",
       "1  0.518868  0.698113  0.783019  0.773585  0.754717  0.754717  0.830189   \n",
       "2  0.509434  0.650943  0.792453  0.830189  0.830189  0.839623  0.849057   \n",
       "3  0.509434  0.641509  0.801887  0.820755  0.811321  0.830189  0.820755   \n",
       "4  0.514286  0.628571  0.800000  0.809524  0.828571  0.828571  0.828571   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0  0.792453  0.792453  0.792453  0.764151  0.792453  0.830189  0.830189   \n",
       "1  0.849057  0.839623  0.839623  0.849057  0.877358  0.877358  0.858491   \n",
       "2  0.839623  0.839623  0.849057  0.839623  0.820755  0.792453  0.811321   \n",
       "3  0.839623  0.830189  0.849057  0.839623  0.830189  0.820755  0.830189   \n",
       "4  0.838095  0.828571  0.847619  0.828571  0.857143  0.819048  0.828571   \n",
       "\n",
       "         14        15        16        17        18        19  \n",
       "0  0.839623  0.764151  0.764151  0.716981  0.745283  0.754717  \n",
       "1  0.896226  0.877358  0.877358  0.792453  0.764151  0.764151  \n",
       "2  0.801887  0.764151  0.792453  0.754717  0.735849  0.688679  \n",
       "3  0.811321  0.849057  0.839623  0.839623  0.792453  0.830189  \n",
       "4  0.847619  0.809524  0.761905  0.733333  0.780952  0.761905  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The performance score for each C in K folds.\n",
    "pd.DataFrame(sparselr.scores_[\"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95aa58bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(np.log10(sparselr.Cs_), sparselr.scores_[\"pos\"].mean(axis=0))\n",
    "plt.xlabel('log(C)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Logistic Regression Path')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a63b62",
   "metadata": {},
   "source": [
    "After running **sparselr.fit**, **sparselr** has already been **retrained** the best $C$ from the grid.\n",
    "\n",
    "Let's evaluate the performance using the best $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52b4881a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:\n",
      "0.998109640831758\n",
      "Test Accuracy:\n",
      "0.8352490421455939\n",
      "Train AUC:\n",
      "0.9999928473334859\n",
      "Test AUC:\n",
      "0.9239297086920628\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy:\")\n",
    "print(accuracy_score(train_y,sparselr.predict(train_x)))\n",
    "print(\"Test Accuracy:\")\n",
    "print(accuracy_score(test_y,sparselr.predict(test_x)))\n",
    "print(\"Train AUC:\")\n",
    "print(roc_auc_score(train_y,sparselr.predict_proba(train_x)[:, 1]))\n",
    "print(\"Test AUC:\")\n",
    "print(roc_auc_score(test_y,sparselr.predict_proba(test_x)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76017c0e",
   "metadata": {},
   "source": [
    "##  Tuning a DTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb69257",
   "metadata": {},
   "source": [
    "In addition to the regularization parameter $C$, the choices we made in the stages of dataset preparation and feature engineering can also affect the DTM, and thus, the performance of a predictive model.\n",
    "    \n",
    "   - Stemming or not\n",
    "   - Remove stop words or not\n",
    "   - Unigram or N-gram\n",
    "   - TF, TFIDF, or Binary\n",
    "   - Unnormalized or normalized\n",
    "   - All unique terms or just top-$K$ terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1307fa3d",
   "metadata": {},
   "source": [
    "Next, we build a SLR based on a DTM in TF and compare with the previous model in their AUC and Accuracy values on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b520c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.SnowballStemmer(\"english\")\n",
    "nltk_stopwords = nltk.corpus.stopwords.words(\"english\") \n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3866eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=StemmedCountVectorizer(stop_words=nltk_stopwords)\n",
    "train_x = vectorizer.fit_transform(df_train[\"Review\"])\n",
    "train_y = df_train[\"Sentiment Polarity\"]\n",
    "test_x = vectorizer.transform(df_test[\"Review\"])\n",
    "test_y = df_test[\"Sentiment Polarity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbb100b",
   "metadata": {},
   "source": [
    "Note that, when we change DTM, **l1_min_c** must be recalculated. So must **param_grid**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf643063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:\n",
      "0.998109640831758\n",
      "Test Accuracy:\n",
      "0.8390804597701149\n",
      "Train AUC:\n",
      "0.9999928473334859\n",
      "Test AUC:\n",
      "0.9255808467979715\n"
     ]
    }
   ],
   "source": [
    "param_grid = l1_min_c(train_x, train_y, loss='log') * np.logspace(start=0, stop=5, num=20) \n",
    "sparselr = LogisticRegressionCV(penalty='l1', \n",
    "                                solver='liblinear', \n",
    "                                Cs=param_grid,   \n",
    "                                cv=5,            \n",
    "                                scoring='accuracy', \n",
    "                                random_state=2021,  \n",
    "                                tol=0.001,\n",
    "                                max_iter=1000)\n",
    "sparselr.fit(train_x, train_y)\n",
    "print(\"Train Accuracy:\")\n",
    "print(accuracy_score(train_y,sparselr.predict(train_x)))\n",
    "print(\"Test Accuracy:\")\n",
    "print(accuracy_score(test_y,sparselr.predict(test_x)))\n",
    "print(\"Train AUC:\")\n",
    "print(roc_auc_score(train_y,sparselr.predict_proba(train_x)[:, 1]))\n",
    "print(\"Test AUC:\")\n",
    "print(roc_auc_score(test_y,sparselr.predict_proba(test_x)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff7af85",
   "metadata": {},
   "source": [
    "It seems TFIDF words better than TF in this example. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785cf763",
   "metadata": {},
   "source": [
    "**More comparisons**\n",
    "\n",
    "\n",
    "\n",
    "| Score | Stemming | N-Gram | Accuracy | AUC |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Unnormalized Tfidf | Yes | Unigram | 0.84 | 0.92 |\n",
    "| Normalized Tfidf | Yes | Unigram | 0.83 | 0.92 |\n",
    "| TF | Yes | Unigram | 0.84 | 0.93 |\n",
    "| TF | No | Bigram | 0.58 | 0.58 |\n",
    "| Binary | Yes | Unigram | 0.86 | 0.93 |\n",
    "| Binary | No | Bigram | 0.64 | 0.72 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b3730",
   "metadata": {},
   "source": [
    "## Decision Tree: A Rule-Based Predictive Model\n",
    "\n",
    "* Using \"decision rules\" to predict the outcome an event.\n",
    "* For example:\n",
    "    - \"A senior student with a high income and an excellent credit-rating will buy a computer from our store.\"\n",
    "    - \"A debtor with age <=25 and debt-to-income ratio>80% will default.\"\n",
    "    - \"An IT help desk ticket containing the term”account\" is about an issue of login.\"\n",
    "\n",
    "* The collection of rules can be represented by a tree diagram\n",
    "    * Example: Predict if someone will cheat on their income tax return based on their marital status, tax income, and whether they are due a tax refund. See the tree below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5763c624",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/decision-tree-ex2.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a3c08a",
   "metadata": {},
   "source": [
    "The **depth** of a tree is the length of the longest path from the **root node** to a **leaf node**.\n",
    "   - The depth of the tree above is three.\n",
    "   - A deision tree with too many leaves and a large depth is very likely to be overfitted. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550c903d",
   "metadata": {},
   "source": [
    "## A Gentle Introduction to XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540222b3",
   "metadata": {},
   "source": [
    "XGBoost is short for \"eXtreme Gradient Boosting\", which is an **ensemble model**. \n",
    "- An ensemble model combines different machine learning models (e.g., decision trees) into one and performs better than individual models. \n",
    "- It is created by the following procedure:\n",
    "    - Learn the first tree from data to minmize the training error. This model usually has a large error.\n",
    "    - Learn the second tree from a random subset to correct the error made by the first tree. \n",
    "    - Learn the third tree from another random subset to correct the error made by the first and second trees.\n",
    "    - The algorithm repeats this procedure until it builds a decent quality mode.\n",
    "    \n",
    "- Eventually, XGBosst makes the prediction by taking the weighted average of the predictions made by all trees.\n",
    "\n",
    "<img src=\"\n",
    "https://www.researchgate.net/profile/Mahsa-Shoaran/publication/325632132/figure/fig2/AS:639244859093006@1529419259793/Schematic-diagram-of-a-boosted-ensemble-of-decision-trees.png\" width=\"500\">\n",
    "\n",
    "- The \"eXtreme\" refers to speed enhancements such as parallel computing and cache awareness that makes XGBoost approximately 10 times faster than traditional Gradient Boosting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc27d21",
   "metadata": {},
   "source": [
    "XGBoost's popularity surged because:\n",
    "   - It consistently outperformed comparable machine learning algorithms when making predictions from tabular data (structured data). \n",
    "   - First-prize winner in many Kaggle competitions. \n",
    "   - Hard to get overfitted.\n",
    "   - Very fast.\n",
    "   - Easy to implement in scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6801eb66",
   "metadata": {},
   "source": [
    "A book on XGBoost: \n",
    "https://www.amazon.com/Hands-Gradient-Boosting-XGBoost-scikit-learn-ebook/dp/B08GSSGTYF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cd07d3",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59381d2",
   "metadata": {},
   "source": [
    "A library for xgboost that provides sklearn API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e926ea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25c952de",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb=XGBClassifier(n_estimators=200,    #How many trees in total\n",
    "                  max_depth=5,         #The depth of each tree\n",
    "                  nthread=4,           #Multi-thread speed up\n",
    "                  use_label_encoder=False,  #To avoid an unimportant warning message \n",
    "                  verbosity = 0,       #Hidden other messages during training\n",
    "                  random_state=2021)   #Fix the results of random sampling during training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2352285a",
   "metadata": {},
   "source": [
    "More options can be found:\n",
    "https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2801a7",
   "metadata": {},
   "source": [
    "**XGBClassifier** require numeric class labels (e.g., 0=neg and 1=pos) so we need to encode the labels first. By default, the alphabetically last label will be encoded into 1 and the other label will become 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e261eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "train_y=le.fit_transform(train_y)\n",
    "test_y=le.transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b395db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=200,\n",
       "              n_jobs=4, nthread=4, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "              random_state=2021, reg_alpha=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=200,\n",
       "              n_jobs=4, nthread=4, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "              random_state=2021, reg_alpha=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=200,\n",
       "              n_jobs=4, nthread=4, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=2021, reg_alpha=0, ...)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4504f5",
   "metadata": {},
   "source": [
    "## Descriptive Analytics (XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650b9dc8",
   "metadata": {},
   "source": [
    "Gradient boosting calculates an importance score for each term that indicates how useful that term was in the construction of the decision trees within the model. \n",
    "\n",
    "The more useful a term is in making a prediction, the higher its importance is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e2e134c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importance score\n",
    "xgb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ced1647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abromeland/.local/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sleek</td>\n",
       "      <td>0.039415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fantast</td>\n",
       "      <td>0.037282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love</td>\n",
       "      <td>0.033920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>perfect</td>\n",
       "      <td>0.029883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amaz</td>\n",
       "      <td>0.025804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>start</td>\n",
       "      <td>0.023955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>disappoint</td>\n",
       "      <td>0.021148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>built</td>\n",
       "      <td>0.020613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>allow</td>\n",
       "      <td>0.018195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wast</td>\n",
       "      <td>0.017326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Term  Importance\n",
       "0       sleek    0.039415\n",
       "1     fantast    0.037282\n",
       "2        love    0.033920\n",
       "3     perfect    0.029883\n",
       "4        amaz    0.025804\n",
       "5       start    0.023955\n",
       "6  disappoint    0.021148\n",
       "7       built    0.020613\n",
       "8       allow    0.018195\n",
       "9        wast    0.017326"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfbeta = pd.DataFrame({'Term': vectorizer.get_feature_names(),\n",
    "                       'Importance': xgb.feature_importances_\n",
    "                     })\n",
    "dfbeta.sort_values(by=\"Importance\",inplace=True,ascending=False)\n",
    "dfbeta.reset_index(inplace=True,drop=True)\n",
    "dfbeta.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0a421c",
   "metadata": {},
   "source": [
    "Compared to $\\beta$'s in sparse logistic regression, importance score does not distinguish terms with positive and negative impact. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f171a180",
   "metadata": {},
   "source": [
    "## Predictive Analytics  (XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b53153",
   "metadata": {},
   "source": [
    "Predictions by XGBoost are implemented in a way similar to SLR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7dc55147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply the model to the reviews testing set and predict the classes\n",
    "xgb.predict(test_x)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f972e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9743140e-01, 2.5685935e-03],\n",
       "       [9.8153418e-01, 1.8465804e-02],\n",
       "       [1.6362548e-01, 8.3637452e-01],\n",
       "       [9.8455006e-01, 1.5449947e-02],\n",
       "       [8.1260675e-01, 1.8739323e-01],\n",
       "       [7.3560524e-01, 2.6439476e-01],\n",
       "       [9.7903705e-01, 2.0962974e-02],\n",
       "       [7.1437037e-01, 2.8562966e-01],\n",
       "       [8.0102682e-04, 9.9919897e-01],\n",
       "       [6.4550185e-01, 3.5449812e-01]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the probability in each class (in alphabetical order of the classes)\n",
    "xgb.predict_proba(test_x)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21f1f99b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:\n",
      "0.996219281663516\n",
      "Test Accuracy:\n",
      "0.8314176245210728\n",
      "Train AUC:\n",
      "0.9999713893339437\n",
      "Test AUC:\n",
      "0.8897275622125251\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy:\")\n",
    "print(accuracy_score(train_y,xgb.predict(train_x)))\n",
    "print(\"Test Accuracy:\")\n",
    "print(accuracy_score(test_y,xgb.predict(test_x)))\n",
    "print(\"Train AUC:\")\n",
    "print(roc_auc_score(train_y,xgb.predict_proba(train_x)[:, 1]))\n",
    "print(\"Test AUC:\")\n",
    "print(roc_auc_score(test_y,xgb.predict_proba(test_x)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc20590",
   "metadata": {},
   "source": [
    "## Cross Validation (XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40073b5",
   "metadata": {},
   "source": [
    "The performance of XGBoost depends on many tuning parameters:\n",
    "   - max_depth: typically between 2 and 20\n",
    "   - n_estimators: typically between 100 and 500\n",
    "   - Others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7562af1",
   "metadata": {},
   "source": [
    "In sklearn, parameters in XGBoost can be selected by $K$-fold cross validation using **GridSearchCV**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74e494de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=2021, reg_alpha=None, ...),\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 5], &#x27;n_estimators&#x27;: [10, 100]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=2021, reg_alpha=None, ...),\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 5], &#x27;n_estimators&#x27;: [10, 100]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, gamma=None,\n",
       "              gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              nthread=4, num_parallel_tree=None, predictor=None,\n",
       "              random_state=2021, reg_alpha=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, gamma=None,\n",
       "              gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              nthread=4, num_parallel_tree=None, predictor=None,\n",
       "              random_state=2021, reg_alpha=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=2021, reg_alpha=None, ...),\n",
       "             param_grid={'max_depth': [2, 5], 'n_estimators': [10, 100]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV   \n",
    "param_list = {  \n",
    " 'max_depth':[2, 5],       #Candidate for max_depth\n",
    " 'n_estimators':[10, 100]  #Candidate for n_estimators\n",
    "}\n",
    "xgb=XGBClassifier(nthread=4,\n",
    "                  use_label_encoder=False,\n",
    "                  verbosity = 0,\n",
    "                  random_state=2021\n",
    "                 )\n",
    "xgb = GridSearchCV(estimator = xgb, \n",
    "                   param_grid = param_list,\n",
    "                   scoring = 'accuracy',  #The performance metric to select the best parameters.\n",
    "                   cv=5                   #Number of folds, i.e., K\n",
    "                  )  \n",
    "xgb.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9336a336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.761815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.831788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.812902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.795885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_max_depth param_n_estimators  mean_test_score\n",
       "0               2                 10         0.761815\n",
       "1               2                100         0.831788\n",
       "2               5                 10         0.812902\n",
       "3               5                100         0.795885"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The averaged performance for each combination of parameters.\n",
    "pd.DataFrame(xgb.cv_results_)[[\"param_max_depth\",\"param_n_estimators\",\"mean_test_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0251f546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 2, 'n_estimators': 100}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the best combination of parameters.\n",
    "xgb.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe152fc",
   "metadata": {},
   "source": [
    "Evaluate the performance using the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "197d4785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:\n",
      "0.9697542533081286\n",
      "Test Accuracy:\n",
      "0.8352490421455939\n",
      "Train AUC:\n",
      "0.9962734607461662\n",
      "Test AUC:\n",
      "0.9108975114989976\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy:\")\n",
    "print(accuracy_score(train_y,xgb.predict(train_x)))\n",
    "print(\"Test Accuracy:\")\n",
    "print(accuracy_score(test_y,xgb.predict(test_x)))\n",
    "print(\"Train AUC:\")\n",
    "print(roc_auc_score(train_y,xgb.predict_proba(train_x)[:, 1]))\n",
    "print(\"Test AUC:\")\n",
    "print(roc_auc_score(test_y,xgb.predict_proba(test_x)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e24ea60",
   "metadata": {},
   "source": [
    "Similarly, we can further improve the performance of XGBoost by using different DTMs. Since the procedure is identical to that of SLR, we omit the details. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ec545f",
   "metadata": {},
   "source": [
    "XBG library does not do re-train. Hence, after knowing the best parameters from cross validation, we need to use them to build a final XGB model (re-train by ourselves). See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ab3f156",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=2, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=4, nthread=4, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "              random_state=2021, reg_alpha=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=2, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=4, nthread=4, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "              random_state=2021, reg_alpha=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=2, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=4, nthread=4, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=2021, reg_alpha=0, ...)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb=XGBClassifier(max_depth=2,\n",
    "                  n_estimators=100,\n",
    "                  nthread=4,\n",
    "                  use_label_encoder=False,\n",
    "                  verbosity = 0,\n",
    "                  random_state=2021\n",
    "                 )\n",
    "xgb.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae88b35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abromeland/.local/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>0.057615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best</td>\n",
       "      <td>0.038459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>easi</td>\n",
       "      <td>0.038394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>perfect</td>\n",
       "      <td>0.038254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amaz</td>\n",
       "      <td>0.028104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>great</td>\n",
       "      <td>0.026452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>high</td>\n",
       "      <td>0.020725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>end</td>\n",
       "      <td>0.019928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sleek</td>\n",
       "      <td>0.019905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>disappoint</td>\n",
       "      <td>0.018073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Term  Importance\n",
       "0        love    0.057615\n",
       "1        best    0.038459\n",
       "2        easi    0.038394\n",
       "3     perfect    0.038254\n",
       "4        amaz    0.028104\n",
       "5       great    0.026452\n",
       "6        high    0.020725\n",
       "7         end    0.019928\n",
       "8       sleek    0.019905\n",
       "9  disappoint    0.018073"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfbeta = pd.DataFrame({'Term': vectorizer.get_feature_names(),\n",
    "                       'Importance': xgb.feature_importances_\n",
    "                     })\n",
    "dfbeta.sort_values(by=\"Importance\",inplace=True,ascending=False)\n",
    "dfbeta.reset_index(inplace=True,drop=True)\n",
    "dfbeta.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
