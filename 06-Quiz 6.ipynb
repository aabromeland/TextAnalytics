{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a52b846",
   "metadata": {},
   "source": [
    "# Quiz 6\n",
    "**5 Points**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6238b5",
   "metadata": {},
   "source": [
    "Is each of the following statement true or false? Type \"True\" or \"False\" in the provided text cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d838d0bb",
   "metadata": {},
   "source": [
    "1. (1 point) Using a large tolerance (\"tol\") will increase the runtime for training a sparse logistic regression model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3affa0e6",
   "metadata": {},
   "source": [
    "You answer: False\n",
    "\n",
    "Speed up the runtime - Stop earlier - premature model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f098e38",
   "metadata": {},
   "source": [
    "2. (1 point) When applying K-fold cross validation to tune parameter $C$ in a sparse logistic regression, the candidates are usually created as a sequence of numbers that increase proportionally instead of additively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3080f5d",
   "metadata": {},
   "source": [
    "Your answer: True "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5c0403",
   "metadata": {},
   "source": [
    "The following code reads a collection of SMS messages with each message labeled as ham (legitimate) or spam. The code also splits the data into training and testing sets and create the DTMs and class labels on both sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e290342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"classdata/spam.csv\")\n",
    "\n",
    "#Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size=0.3, random_state=2021)\n",
    "df_train.reset_index(drop=True,inplace=True)\n",
    "df_test.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#Feature Engineering\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import nltk \n",
    "\n",
    "stemmer = nltk.stem.SnowballStemmer(\"english\")\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedTfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "\n",
    "nltk_stopwords = nltk.corpus.stopwords.words(\"english\") \n",
    "\n",
    "vectorizer=StemmedTfidfVectorizer(stop_words=nltk_stopwords, norm=None)\n",
    "\n",
    "#Create the training and testing DTMs and the labels\n",
    "train_x = vectorizer.fit_transform(df_train[\"Message\"])\n",
    "train_y = df_train[\"Label\"]\n",
    "test_x = vectorizer.transform(df_test[\"Message\"])\n",
    "test_y = df_test[\"Label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d5172d",
   "metadata": {},
   "source": [
    "3. (3 points) Build a XGBoost model that predicts if a message is spam or ham. Your XGBoost model must consist of 300 trees with depth 3. Other parameters should be set as follows\n",
    "\n",
    "   * nthread=4\n",
    "   * use_label_encoder=False\n",
    "   * verbosity = 0\n",
    "   * random_state=2021\n",
    "\n",
    "Use **train_x** and **train_y** created above to build the model. Recall that **XGBClassifier** requires numeric class labels (e.g., 0=ham and 1=spam) so you need to encode **train_y** into 0 and 1 first. You are done after training. No need to apply the model to the testing set for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61da5d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=300,\n",
       "              n_jobs=4, nthread=4, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "              random_state=2021, reg_alpha=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=300,\n",
       "              n_jobs=4, nthread=4, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "              random_state=2021, reg_alpha=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=300,\n",
       "              n_jobs=4, nthread=4, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=2021, reg_alpha=0, ...)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your answer here:\n",
    "from sklearn import preprocessing\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb=XGBClassifier(n_estimators=300,    #How many trees in total\n",
    "                  max_depth=3,         #The depth of each tree\n",
    "                  nthread=4,           #Multi-thread speed up\n",
    "                  use_label_encoder=False,  #To avoid an unimportant warning message \n",
    "                  verbosity = 0,       #Hidden other messages during training\n",
    "                  random_state=2021)   #Fix the results of random sampling during training\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "train_y=le.fit_transform(train_y)\n",
    "\n",
    "xgb.fit(train_x, train_y)\n",
    "\n",
    "#Check your answer:\n",
    "xgb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
