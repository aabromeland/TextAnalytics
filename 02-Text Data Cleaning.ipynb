{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3fbfb1b",
   "metadata": {},
   "source": [
    "# Text Data Cleaning | BAIS 6100\n",
    "\n",
    "**Instructor: Qihang Lin**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e67aed",
   "metadata": {},
   "source": [
    "## Data Cleaning is Necessary\n",
    "\n",
    "1. Remove non-informative content or noise. \n",
    "2. Extract useful information. (e.g. find all emails or phone numbers).\n",
    "3. Prepare for counting word frequency.\n",
    "    * Convert a phrase into a string (e.g. \"White House\" to \"WhiteHouse\").\n",
    "    * Convert a string into a phrase (e.g. \"we'll\" to \"we will\").\n",
    "    * Remove or replace punctuations or numbers.\n",
    "    * Remove stop words.\n",
    "    * Stemming or lemmatization.\n",
    "    * ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cca9923",
   "metadata": {},
   "source": [
    "**NLTK** is a suite of libraries and programs for natural language processing and it has become one of the most important libraries for text analytics in practices.\n",
    "\n",
    "We need to use **nltk** library and **regular expression** for advanced text data clearning and term frequency counting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dbfbec",
   "metadata": {},
   "source": [
    "If that's the first time you run the code in this notebook, please uncomment and run the following commands to install necessary packages and NLTK modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fac67a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in ./.local/lib/python3.9/site-packages (3.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in ./.local/lib/python3.9/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.local/lib/python3.9/site-packages (from nltk) (2022.4.24)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.9/site-packages (from nltk) (4.64.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/abromeland/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/abromeland/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/abromeland/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package brown to /home/abromeland/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /home/abromeland/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/treebank.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/abromeland/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip3 install --upgrade nltk\n",
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('brown')\n",
    "#nltk.download('treebank')\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "065a6ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter              # for word counting\n",
    "import nltk                                  # for text clearning\n",
    "import itertools                             # to flatten a list of lists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7ceb4a",
   "metadata": {},
   "source": [
    "Load the data we need for this lecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea47bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"classdata/clinton-street-social-club.csv\",encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b9ac27",
   "metadata": {},
   "source": [
    "## Word Frequency Counts before Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e688d2b",
   "metadata": {},
   "source": [
    "Suppose we want to see the word frequency counts in the customer reviews but we directly process the raw data without any cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84855dc",
   "metadata": {},
   "source": [
    "Take the first review as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec0a2b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"With its jazzy vibes and chill atmosphere, Clinton Street Social Club itself may just be the speakeasy of Iowa City. It's entrance is through a small door next to Shorts burgers and a barber shop. If you don't know what you're looking for, you may never find it. \\r\\n\\r\\nIn all seriousness they mimic New Orleans culture and have the most delicious food and creative alcoholic beverages. Must try are their beignets, shrimp cocktail, house-batterer curds, sweet corn fritters! \\r\\n\\r\\nFor alcoholic drinks, I loved their Ramos Gin Fizz the most! I tend to not like anything where I can taste the alcohol and this one has just the right balance. It's has the right amount of fizz with added foam from the egg whites. Very unique compared to the usual bars located downtown. \\r\\n\\r\\nI had the opportunity to learn how to tend bar from the all knowing bartender Joy, that girl definitely knows her alcohol. She made us delicious drinks as told us all about its historical discovery.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"reviews\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cc13c5",
   "metadata": {},
   "source": [
    "Let's use the default tokenizer in NLTK to tokenize the first review and see what is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7db8e8a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['With', 'its', 'jazzy', 'vibes', 'and', 'chill', 'atmosphere', ',', 'Clinton', 'Street', 'Social', 'Club', 'itself', 'may', 'just', 'be', 'the', 'speakeasy', 'of', 'Iowa', 'City', '.', 'It', \"'s\", 'entrance', 'is', 'through', 'a', 'small', 'door', 'next', 'to', 'Shorts', 'burgers', 'and', 'a', 'barber', 'shop', '.', 'If', 'you', 'do', \"n't\", 'know', 'what', 'you', \"'re\", 'looking', 'for', ',', 'you', 'may', 'never', 'find', 'it', '.', 'In', 'all', 'seriousness', 'they', 'mimic', 'New', 'Orleans', 'culture', 'and', 'have', 'the', 'most', 'delicious', 'food', 'and', 'creative', 'alcoholic', 'beverages', '.', 'Must', 'try', 'are', 'their', 'beignets', ',', 'shrimp', 'cocktail', ',', 'house-batterer', 'curds', ',', 'sweet', 'corn', 'fritters', '!', 'For', 'alcoholic', 'drinks', ',', 'I', 'loved', 'their', 'Ramos', 'Gin', 'Fizz', 'the', 'most', '!', 'I', 'tend', 'to', 'not', 'like', 'anything', 'where', 'I', 'can', 'taste', 'the', 'alcohol', 'and', 'this', 'one', 'has', 'just', 'the', 'right', 'balance', '.', 'It', \"'s\", 'has', 'the', 'right', 'amount', 'of', 'fizz', 'with', 'added', 'foam', 'from', 'the', 'egg', 'whites', '.', 'Very', 'unique', 'compared', 'to', 'the', 'usual', 'bars', 'located', 'downtown', '.', 'I', 'had', 'the', 'opportunity', 'to', 'learn', 'how', 'to', 'tend', 'bar', 'from', 'the', 'all', 'knowing', 'bartender', 'Joy', ',', 'that', 'girl', 'definitely', 'knows', 'her', 'alcohol', '.', 'She', 'made', 'us', 'delicious', 'drinks', 'as', 'told', 'us', 'all', 'about', 'its', 'historical', 'discovery', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(df[\"reviews\"][0])   #Tokenize the first reivew. \n",
    "print(tokens)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c754b0",
   "metadata": {},
   "source": [
    "A few interesting observations:\n",
    "- , . and ! are treated as tokens but ' is not.\n",
    "- \"don't\" is splitted into \"do\" and \"n't\" two tokens. Similar case for \"isn't\", \"aren't\", and \"can't\".\n",
    "- \"It's\" and \"you're\" are splitted into \"It\", \"'s\" and \"you\", \"'re\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74dea77",
   "metadata": {},
   "source": [
    "Use list comprehension to tokenize each review and return the list of tokens from each review as a \"list of lists\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92f82244",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_all = [nltk.word_tokenize(s) for s in df[\"reviews\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2e678a",
   "metadata": {},
   "source": [
    "**words_all** is \"list of lists\" and, because of that, we cannot count the word frequency directly using words_all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e502b75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['With', 'its', 'jazzy', 'vibes', 'and', 'chill', 'atmosphere', ',', 'Clinton', 'Street', 'Social', 'Club', 'itself', 'may', 'just', 'be', 'the', 'speakeasy', 'of', 'Iowa', 'City', '.', 'It', \"'s\", 'entrance', 'is', 'through', 'a', 'small', 'door', 'next', 'to', 'Shorts', 'burgers', 'and', 'a', 'barber', 'shop', '.', 'If', 'you', 'do', \"n't\", 'know', 'what', 'you', \"'re\", 'looking', 'for', ',', 'you', 'may', 'never', 'find', 'it', '.', 'In', 'all', 'seriousness', 'they', 'mimic', 'New', 'Orleans', 'culture', 'and', 'have', 'the', 'most', 'delicious', 'food', 'and', 'creative', 'alcoholic', 'beverages', '.', 'Must', 'try', 'are', 'their', 'beignets', ',', 'shrimp', 'cocktail', ',', 'house-batterer', 'curds', ',', 'sweet', 'corn', 'fritters', '!', 'For', 'alcoholic', 'drinks', ',', 'I', 'loved', 'their', 'Ramos', 'Gin', 'Fizz', 'the', 'most', '!', 'I', 'tend', 'to', 'not', 'like', 'anything', 'where', 'I', 'can', 'taste', 'the', 'alcohol', 'and', 'this', 'one', 'has', 'just', 'the', 'right', 'balance', '.', 'It', \"'s\", 'has', 'the', 'right', 'amount', 'of', 'fizz', 'with', 'added', 'foam', 'from', 'the', 'egg', 'whites', '.', 'Very', 'unique', 'compared', 'to', 'the', 'usual', 'bars', 'located', 'downtown', '.', 'I', 'had', 'the', 'opportunity', 'to', 'learn', 'how', 'to', 'tend', 'bar', 'from', 'the', 'all', 'knowing', 'bartender', 'Joy', ',', 'that', 'girl', 'definitely', 'knows', 'her', 'alcohol', '.', 'She', 'made', 'us', 'delicious', 'drinks', 'as', 'told', 'us', 'all', 'about', 'its', 'historical', 'discovery', '.'], ['This', 'was', 'an', 'exceptional', 'surprise', 'in', 'Iowa', 'city', '!', 'You', 'would', 'find', 'this', 'in', 'someplace', 'like', 'New', 'York', 'or', 'San', 'Francisco', 'or', 'Seattle', '!', 'The', 'drink', 'menu', 'is', 'amazing', ',', 'what', 'I', 'can', 'remember', 'of', 'it', 'LOL', '.', 'The', 'Korean', 'fried', 'chicken', 'and', 'mac', '&', 'cheese', 'were', 'a', 'delightful', 'pairing', 'together', '.', 'The', 'service', 'was', 'outstanding', 'and', 'the', 'atmosphere', 'was', 'simply', 'delightful', '!', 'I', 'would', 'highly', 'recommend', 'this', 'place', 'to', 'any', 'serious', 'Foodie', '!']]\n"
     ]
    }
   ],
   "source": [
    "print(words_all[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978340ad",
   "metadata": {},
   "source": [
    "Use **itertools.chain.from_iterable** to \"flatten\" a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "022986ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List of words across all reviews\n",
    "words_all = list(itertools.chain.from_iterable(words_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "529bb7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['With', 'its', 'jazzy', 'vibes', 'and', 'chill', 'atmosphere', ',', 'Clinton', 'Street', 'Social', 'Club', 'itself', 'may', 'just', 'be', 'the', 'speakeasy', 'of', 'Iowa', 'City', '.', 'It', \"'s\", 'entrance', 'is', 'through', 'a', 'small', 'door', 'next', 'to', 'Shorts', 'burgers', 'and', 'a', 'barber', 'shop', '.', 'If', 'you', 'do', \"n't\", 'know', 'what', 'you', \"'re\", 'looking', 'for', ',', 'you', 'may', 'never', 'find', 'it', '.', 'In', 'all', 'seriousness', 'they', 'mimic', 'New', 'Orleans', 'culture', 'and', 'have', 'the', 'most', 'delicious', 'food', 'and', 'creative', 'alcoholic', 'beverages', '.', 'Must', 'try', 'are', 'their', 'beignets', ',', 'shrimp', 'cocktail', ',', 'house-batterer', 'curds', ',', 'sweet', 'corn', 'fritters', '!', 'For', 'alcoholic', 'drinks', ',', 'I', 'loved', 'their', 'Ramos', 'Gin', 'Fizz', 'the', 'most', '!', 'I', 'tend', 'to', 'not', 'like', 'anything', 'where', 'I', 'can', 'taste', 'the', 'alcohol', 'and', 'this', 'one', 'has', 'just', 'the', 'right', 'balance', '.', 'It', \"'s\", 'has', 'the', 'right', 'amount', 'of', 'fizz', 'with', 'added', 'foam', 'from', 'the', 'egg', 'whites', '.', 'Very', 'unique', 'compared', 'to', 'the', 'usual', 'bars', 'located', 'downtown', '.', 'I', 'had', 'the', 'opportunity', 'to', 'learn', 'how', 'to', 'tend', 'bar', 'from', 'the', 'all', 'knowing', 'bartender', 'Joy', ',', 'that', 'girl', 'definitely', 'knows', 'her', 'alcohol', '.', 'She', 'made', 'us', 'delicious', 'drinks', 'as', 'told', 'us', 'all', 'about', 'its', 'historical', 'discovery', '.', 'This', 'was', 'an', 'exceptional', 'surprise', 'in', 'Iowa', 'city', '!', 'You', 'would']\n"
     ]
    }
   ],
   "source": [
    "print(words_all[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7610724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 1022),\n",
       " ('the', 741),\n",
       " (',', 623),\n",
       " ('and', 566),\n",
       " ('a', 491),\n",
       " ('I', 370),\n",
       " ('to', 334),\n",
       " ('of', 285),\n",
       " ('was', 233),\n",
       " ('is', 217),\n",
       " ('in', 197),\n",
       " ('The', 190),\n",
       " ('for', 186),\n",
       " ('!', 162),\n",
       " ('it', 160),\n",
       " ('that', 141),\n",
       " ('with', 138),\n",
       " ('but', 125),\n",
       " ('had', 121),\n",
       " ('have', 117)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create counter and show 20 most frequent tokens.\n",
    "counts = Counter(words_all)\n",
    "counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250be8a4",
   "metadata": {},
   "source": [
    "**counts.most_common()** returns a list of **tuple**s. A tuple, for example, ('.', 1022), is represented by enclosing the items in parentheses () instead of square brackerts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32a206e",
   "metadata": {},
   "source": [
    "It will be more intuitive to convert tuples into a data frame. This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b151a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>to</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>was</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>is</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Term  Frequency\n",
       "0    .       1022\n",
       "1  the        741\n",
       "2    ,        623\n",
       "3  and        566\n",
       "4    a        491\n",
       "5    I        370\n",
       "6   to        334\n",
       "7   of        285\n",
       "8  was        233\n",
       "9   is        217"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dffreq = pd.DataFrame(counts.most_common(), columns=['Term', 'Frequency'])\n",
    "dffreq.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c69840",
   "metadata": {},
   "source": [
    "Any concerns about the word frequency counted this way? Shall we count punctuations and stop words?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25be4af8",
   "metadata": {},
   "source": [
    "## Word Frequency Counts after Clearning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a7971c",
   "metadata": {},
   "source": [
    "The following steps of clearning can be done to make the frequency counts more reasonable. Depending on the use case, some steps can be modified or skipped. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbde09d",
   "metadata": {},
   "source": [
    "### 1. Turn letters to lower cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe70e3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"with its jazzy vibes and chill atmosphere, clinton street social club itself may just be the speakeasy of iowa city. it's entrance is through a small door next to shorts burgers and a barber shop. if you don't know what you're looking for, you may never find it. \\r\\n\\r\\nin all seriousness they mimic new orleans culture and have the most delicious food and creative alcoholic beverages. must try are their beignets, shrimp cocktail, house-batterer curds, sweet corn fritters! \\r\\n\\r\\nfor alcoholic drinks, i loved their ramos gin fizz the most! i tend to not like anything where i can taste the alcohol and this one has just the right balance. it's has the right amount of fizz with added foam from the egg whites. very unique compared to the usual bars located downtown. \\r\\n\\r\\ni had the opportunity to learn how to tend bar from the all knowing bartender joy, that girl definitely knows her alcohol. she made us delicious drinks as told us all about its historical discovery.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"reviews_new\"]=df[\"reviews\"].str.lower()\n",
    "df[\"reviews_new\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3c1f98",
   "metadata": {},
   "source": [
    "### 2. Replace Words if Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b654134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with its jazzy vibes and chill atmosphere, clinton street social club itself may just be the speakeasy of iowacity. it is entrance is through a small door next to shorts burgers and a barber shop. if you do not know what you are looking for, you may never find it. \\r\\n\\r\\nin all seriousness they mimic new orleans culture and have the most delicious food and creative alcoholic beverages. must try are their beignets, shrimp cocktail, house-batterer curds, sweet corn fritters! \\r\\n\\r\\nfor alcoholic drinks, i loved their ramos gin fizz the most! i tend to not like anything where i can taste the alcohol and this one has just the right balance. it is has the right amount of fizz with added foam from the egg whites. very unique compared to the usual bars located downtown. \\r\\n\\r\\ni had the opportunity to learn how to tend bar from the all knowing bartender joy, that girl definitely knows her alcohol. she made us delicious drinks as told us all about its historical discovery.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"reviews_new\"]=df[\"reviews_new\"].str.replace(\"iowa city\",\"iowacity\")\n",
    "df[\"reviews_new\"]=df[\"reviews_new\"].str.replace(\"can't \",\"can not \")\n",
    "df[\"reviews_new\"]=df[\"reviews_new\"].str.replace(\"n't \",\" not \")\n",
    "df[\"reviews_new\"]=df[\"reviews_new\"].str.replace(\"'re \",\" are \")\n",
    "df[\"reviews_new\"]=df[\"reviews_new\"].str.replace(\"'ve \",\" have \")\n",
    "df[\"reviews_new\"]=df[\"reviews_new\"].str.replace(\"'s \",\" is \")\n",
    "df[\"reviews_new\"]=df[\"reviews_new\"].str.replace(\"'m \",\" am \")\n",
    "df[\"reviews_new\"]=df[\"reviews_new\"].str.replace(\"'ll \",\" will \")\n",
    "df[\"reviews_new\"]=df[\"reviews_new\"].str.replace(\"'d \",\" would \")\n",
    "df[\"reviews_new\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa5c216",
   "metadata": {},
   "source": [
    "### 3. Remove all stop words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a3dcc9",
   "metadata": {},
   "source": [
    "Let's take a look at which words are considered as stop words by NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99e3fb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "global_stopwords = nltk.corpus.stopwords.words(\"english\") \n",
    "print(global_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ecc5683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>place</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>good</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>drinks</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>menu</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>one</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Term  Frequency\n",
       "0       .       1017\n",
       "1       ,        623\n",
       "2       !        162\n",
       "3   great        129\n",
       "4    food        106\n",
       "5   place        102\n",
       "6    good         86\n",
       "7  drinks         65\n",
       "8    menu         62\n",
       "9     one         61"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_all = [nltk.word_tokenize(s) for s in df[\"reviews_new\"]]\n",
    "words_all = list(itertools.chain.from_iterable(words_all))\n",
    "words_all = [s for s in words_all if s not in global_stopwords]\n",
    "counts = Counter(words_all)\n",
    "dffreq = pd.DataFrame(counts.most_common(), columns=['Term', 'Frequency'])\n",
    "dffreq.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c02f9f",
   "metadata": {},
   "source": [
    "Here, we use the if statement ''**if s not in global_stopwords**'' in list comprehension so that only the string not in **global_stopwords** will be added to the output list. \n",
    "\n",
    "The condition in the if statement can be modified to handle other requirements. See the example in the next step below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a98bbb7",
   "metadata": {},
   "source": [
    "### 4. Remove all short tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b62262b",
   "metadata": {},
   "source": [
    "We will remove tokens shorter than three. This will effectively remove the tokens that are punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f42f670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>food</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>place</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drinks</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>menu</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>one</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cheese</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>like</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bar</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Term  Frequency\n",
       "0   great        129\n",
       "1    food        106\n",
       "2   place        102\n",
       "3    good         86\n",
       "4  drinks         65\n",
       "5    menu         62\n",
       "6     one         61\n",
       "7  cheese         60\n",
       "8    like         58\n",
       "9     bar         58"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_all = [s for s in words_all if len(s)>2]\n",
    "counts = Counter(words_all)\n",
    "dffreq = pd.DataFrame(counts.most_common(), columns=['Term', 'Frequency'])\n",
    "dffreq.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e92c04b",
   "metadata": {},
   "source": [
    "### 5. Stemming "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da31ee91",
   "metadata": {},
   "source": [
    "Lemmatization requires POS tagging to achieve its best performance. In this lecture, we will focus on stemming. We need to first create a stemmer, e.g. SnowballStemmer, for English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8772067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.SnowballStemmer(\"english\")\n",
    "#stemmer = nltk.stem.PorterStemmer() #is less aggressive\n",
    "#stemmer = nltk.stem.LancasterStemmer() #is more aggressive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f7e5f2",
   "metadata": {},
   "source": [
    "Let's see a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90588b56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nation'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"nationality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e63a7085",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'busi'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"businesses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cee2d85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'busi'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"busy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b7bbe35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buse'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"buses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "338b49e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'citi'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b4d7a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'drink'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"drinks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8721c1d3",
   "metadata": {},
   "source": [
    "Some cases might cause problems (e.g. \"business\" and \"busy\"). NLP is not perfect. We can live with it but need to be aware of these potential issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca4211b",
   "metadata": {},
   "source": [
    "Apply stemming to each token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4797f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>place</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drink</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>food</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cocktail</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>time</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bar</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>order</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>one</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Term  Frequency\n",
       "0     great        129\n",
       "1     place        117\n",
       "2     drink        116\n",
       "3      food        107\n",
       "4      good         87\n",
       "5  cocktail         78\n",
       "6      time         72\n",
       "7       bar         70\n",
       "8     order         65\n",
       "9       one         64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_all = [stemmer.stem(s) for s in words_all]\n",
    "counts = Counter(words_all)\n",
    "dffreq = pd.DataFrame(counts.most_common(), columns=['Term', 'Frequency'])\n",
    "dffreq.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad27cea",
   "metadata": {},
   "source": [
    "## The Order  Matters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d838df1e",
   "metadata": {},
   "source": [
    "Applying the clearning steps in different orders may affect the frequency counts. Change and modify the orders according to your situation.\n",
    "\n",
    "* A stop word is case senstitive. \"There\" is not a stop word but \"there\" is.\n",
    "* \"'re\" is not a stop word but \"are\" is.\n",
    "* \"going\" is longer then two characters but \"go\" isn't.\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b7a30b",
   "metadata": {},
   "source": [
    "## Other Steps to Consider\n",
    "-  Customize the stop word list.\n",
    "-  Remove all punctuations and all digits.\n",
    "-  Create **group tokens**\n",
    "      -  Remove/replace all dollar amounts by a group token like \"dollaramount\". \n",
    "      -  Remove/replace all urls by a group token like \"urltoken\".\n",
    "      -  ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f048d79",
   "metadata": {},
   "source": [
    "## Customize the List of Stop Words "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c361680",
   "metadata": {},
   "source": [
    "It may happen that some words are not considered as stop words but also not interesting for frequency counting. For examples, 'also' and 'would'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce433e5",
   "metadata": {},
   "source": [
    "It may also happen you want to keep some stop words in the frequency counts, for example, \"not\" and \"can\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571ab5c3",
   "metadata": {},
   "source": [
    "In these situation, it is useful to know how to customize the stop word list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01156d0",
   "metadata": {},
   "source": [
    "Remove stop words from the default list and add new stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "518bec44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'also', 'would']\n"
     ]
    }
   ],
   "source": [
    "global_stopwords = nltk.corpus.stopwords.words(\"english\") \n",
    "global_stopwords.remove(\"not\")\n",
    "global_stopwords.remove(\"can\")\n",
    "global_stopwords = global_stopwords+[\"also\",\"would\"]\n",
    "print(global_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef635567",
   "metadata": {},
   "source": [
    "Repeat every step once again using the new stop word list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "897f3a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>place</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drink</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>good</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cocktail</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>time</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bar</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>order</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Term  Frequency\n",
       "0       not        181\n",
       "1     great        129\n",
       "2     place        117\n",
       "3     drink        116\n",
       "4      food        107\n",
       "5      good         87\n",
       "6  cocktail         78\n",
       "7      time         72\n",
       "8       bar         70\n",
       "9     order         65"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_all = [nltk.word_tokenize(s) for s in df[\"reviews_new\"]]\n",
    "words_all = list(itertools.chain.from_iterable(words_all))\n",
    "words_all = [s for s in words_all if s not in global_stopwords]\n",
    "words_all = [s for s in words_all if len(s)>2]\n",
    "words_all = [stemmer.stem(s) for s in words_all]\n",
    "counts = Counter(words_all)\n",
    "dffreq = pd.DataFrame(counts.most_common(), columns=['Term', 'Frequency'])\n",
    "dffreq.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7381cc0a",
   "metadata": {},
   "source": [
    "## Process Strings by Regular Expression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0c5e77",
   "metadata": {},
   "source": [
    "We have learned how to use string processing functions (the basic ones and the .str methods) to modify strings. However, the string pattern we search using these functions must be literally matched. \n",
    "\n",
    "What if the string pattern we want to search is a more general pattern? For example, how can we remove all punctuations or all digits in a string?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b9bec0",
   "metadata": {},
   "source": [
    "We can use <b>re</b> library and **regular expression** to describe a string pattern in a more general and flexible way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f6cb29",
   "metadata": {},
   "source": [
    "Regular expression is used in almost all programming languages. It is a very sophisticated technique and lots of practice is necessary in order to become a proficient user. We will only cover some basic expressions. If you are interested to study RE with more depth, read https://www.tutorialspoint.com/python/python_reg_expressions.htm and http://webagility.com/posts/the-basics-of-regex-explained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1fb860",
   "metadata": {},
   "source": [
    "We will first study REs representing character classes and then REs representing string patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c790822",
   "metadata": {},
   "source": [
    "## Regular Expression for Classes of Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b924b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe4fb99",
   "metadata": {},
   "source": [
    "A few commonly used examples that represent a class of characters:\n",
    "\n",
    "|     Regular  | Expression|\n",
    "-:|:- \n",
    "`\\d` | Any digit\n",
    "`\\w` | Any alphanumerical character and the underscore \"_\"\n",
    "`\\s` | Whitespace, tab, or newline\n",
    "**Their complements** |\n",
    "`\\D` | Any character not in '\\d'\n",
    "`\\W` | Any character not in '\\w'\n",
    "`\\S` | Any character not in '\\s'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987a5e97",
   "metadata": {},
   "source": [
    "For historical reasons, underscore \"_\" is used in **identifiers_like_this** in many programming languanges, which makes it special."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf69a6",
   "metadata": {},
   "source": [
    "We use the following string as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b561e421",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John said: \"He was born 1990. Here's his the rÃ©sumÃ©.\" ___ðŸ˜‚\n"
     ]
    }
   ],
   "source": [
    "mystr = 'John said: \"He was born 1990. Here\\'s his the rÃ©sumÃ©.\" ___ðŸ˜‚'\n",
    "print(mystr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0cb26be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John said: \"He was born . Here\\'s his the rÃ©sumÃ©.\" ___ðŸ˜‚'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('\\d', '', mystr)   # Remove all digits (replace by an empty string)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d961a1",
   "metadata": {},
   "source": [
    "## Square Brackets and Ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca2a093",
   "metadata": {},
   "source": [
    "In RE, \"[ ]\" represents \"**anything in the brackets**\" and \"-\" represents \"**from-to**\" :\n",
    "\n",
    "|     Regular  | Expression|\n",
    "-:|:- \n",
    "   `[\\w\\s]` | Anything represented by \"\\w\" or \"\\s\"\n",
    "   `[a12]` | Match \"a\", \"1\" or \"2\". You can add as many as you want.\n",
    "   `[0-9]`    | Any digit (just like \"\\d\")\n",
    "   `[a-z]`    | Any English letter in lower case\n",
    "   `[A-Z]`    | Any English letter in upper case \n",
    "`[a-zA-Z0-9]` | Any digit or any English letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "952eb538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'         : \"                .     \\'           Ã©   Ã©.\" ___ðŸ˜‚'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('[a-zA-Z0-9]', ' ', mystr) #Replace any digit and any English-letter by a whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5fd21d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "':\".\\'.\"ðŸ˜‚'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('[\\w\\s]', '', mystr) #Remove any spacing characters, any digit and any letter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36edfcca",
   "metadata": {},
   "source": [
    "### Not [^]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3a8e62",
   "metadata": {},
   "source": [
    "In RE, \"[^...]\" represents \"**anything not in the brackets**\":\n",
    "\n",
    "|     Regular  | Expression|\n",
    "-:|:- \n",
    "`[^a12]` | Match any character except \"a\", \"1\" and \"2\".\n",
    "`[^a-zA-Z0-9]`    | Anything non-digit and non-English-letter\n",
    "`[^\\w\\s]`    | Anything not in \"\\w\" and \"\\s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea61e10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John said   He was born 1990  Here s his the r sum        '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('[^a-zA-Z0-9]', ' ', mystr) #Replace anything non-digit non-english-letter by a whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8a02622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John said He was born 1990 Heres his the rÃ©sumÃ© ___'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('[^\\w\\s]', '', mystr)  #Remove anything not in \"\\w\" and \"\\s\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ff8b69",
   "metadata": {},
   "source": [
    "## Disjunction of Search Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9262ce",
   "metadata": {},
   "source": [
    "In RE, '|' represents \"OR\". We can use the expression **\"condition1|conditoin2|....|condition10\"** to represent a string satisfies at least one condition from 1 to 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6b89e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John said He was born  Heres his the rÃ©sumÃ© '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('[^\\w\\s]|_|\\d', '', mystr)   #Remove anything that matches '[^\\w\\s]' or \"_\" or \"\\d\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406eeefe",
   "metadata": {},
   "source": [
    "## Other RE Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3401375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(24, 25), match='1'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search('\\d', mystr)       #Search for a digit and return a \"match object\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1462986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use bool to convert the search result to True or False.\n",
    "bool(re.search('\\d', mystr)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "377173ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '9', '9', '0']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('\\d', mystr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413d5e44",
   "metadata": {},
   "source": [
    "See (https://docs.python.org/3/library/re.html) for a complete list of functions from **re**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b2dfc1",
   "metadata": {},
   "source": [
    "Just like string methods, **re** methods will not change the original string unless you overwrite it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f51a1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John said He was born  Heres his the rÃ©sumÃ© '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystr=re.sub('[^\\w\\s]|_|\\d', '', mystr)  \n",
    "mystr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b1da8f",
   "metadata": {},
   "source": [
    "Don't get confused between an escape sequence and a regular expression. They both use '\\\\' in their grammar. An escape sequence (like \"\\\\n\") is an special character but a regular expression (like \"\\d\") represents a class of characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce3ed9",
   "metadata": {},
   "source": [
    "## Regular Expression Using Meta Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c8038",
   "metadata": {},
   "source": [
    "**re** allows using **meta characters** . ^ $ * + ? { } [ ] \\ | ( ) to represent more flexible and general string patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c29beb",
   "metadata": {},
   "source": [
    "We use the following sentence as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65c26cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mystr = \"Want $1,000,000.00? Contact John at john2021@gmail.com or 319-335-0988\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e20768",
   "metadata": {},
   "source": [
    "## Search Pattern at the Beginning or the End"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182f3b21",
   "metadata": {},
   "source": [
    "Let **re** represents a regular expression such as \"\\d\":\n",
    "\n",
    "|     Regular  | Expression|\n",
    "-:|:- \n",
    "^re | Matches **re** at the beginning of the string.\n",
    "re$ | Matches **re** at the end of the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "94f209ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(re.search('^[a-z]', mystr)) #Check if the string begins with a lower letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b7665c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(re.search('\\d$', mystr)) #Check if the string ends with a digit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b98a26e",
   "metadata": {},
   "source": [
    "## Quantifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2144db73",
   "metadata": {},
   "source": [
    "|     Regular  | Expression|\n",
    "-:|:- \n",
    "re* | Matches 0 or more continuous occurrences of **re**.\n",
    "re+ | Matches 1 or more continuous occurrences of **re**.\n",
    "re{2,6}  | Matches 2, 3, 4, 5 or 6 continuous occurrences of **re**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe36b5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '000', '000', '00', '2021', '319', '335', '0988']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('\\d+', mystr)    #Find all continuous occurences of digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e77dd899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Want', 'Contact', 'John']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[A-Z][a-z]*', mystr)  #Find strings starting with A-Z followed by any number of a-z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a589a6de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$1,000,000.00']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('\\$\\d+[\\d,\\.]*', mystr)   #Find all dollar amounts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150eeaaf",
   "metadata": {},
   "source": [
    "Be careful! Here, we have to use the escape sequences \"\\\\$\" and \"\\.\" to represent the dollar sign and the decimal point because \"$\" and \".\" are meta characters and do not mean what they are literally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db7facdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['319-335-0988']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('\\d{3,3}-\\d{3,3}-\\d{3,4}', mystr)  #Find all phone numbers in the format xxx-xxx-xxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f01e731",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['john2021@gmail.com']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('\\S+@\\S+\\.\\S+', mystr)  #Find all email addressess."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b8989b",
   "metadata": {},
   "source": [
    "## Create Group Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5e3343e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Want moneytoken? Contact John at emailtoken or phonenumbertoken'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystr = re.sub('\\$\\d+[\\d,\\.]*', \"moneytoken\", mystr)\n",
    "mystr = re.sub('\\d{3,3}-\\d{3,3}-\\d{4,4}', \"phonenumbertoken\", mystr)\n",
    "mystr = re.sub('\\S+@\\S+\\.\\S+', \"emailtoken\", mystr)\n",
    "mystr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d8903f",
   "metadata": {},
   "source": [
    "With these replacements, all dollar amounts (phone numbers, emails) will be counted as the same token. This is helpful when analyzing text data containing many numbers, for example, economic news. In fact, you don't want to ignore all numbers but also do not want to have so many unique tokens because of the unique numbers in the article. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53fced6",
   "metadata": {},
   "source": [
    "## Apply Regular Expression to Strings in a Column or List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7429111",
   "metadata": {},
   "source": [
    "We can still use list comprehension or the \".str\" methods to apply a regular expression to each string in a list or column. The \".str\" methods actually can recognize regular expression just like \"re\" methods but it only works if the strings is in a column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14497f8c",
   "metadata": {},
   "source": [
    "Example 1: Apply regular expression to find the reviews that mention a dollar amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9320430a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There is no other place in town like CSSC. If you are looking for the speakeasy vibe and views of the ped mall this is the place to be. Grab a Silk Road and share the fondue for a perfect date night with ur SO or BFF.\\r\\n\\r\\nDrinks: Silk Road and Pisco sour if you love egg whites. I love egg white in my cocktails because the foam texture which reminds me of a latte. Annabelle lee is refreshing and they have a selection of whisky / bourbon as well if that's your drink of choice.  Cocktails are $10-$12. Also a handful of beers on tap. \\r\\n\\r\\nFood: LOVE the fondue. Melted with apples and caramelizad onions. The poutine is also very popular and I've enjoyed their burger. \\r\\n\\r\\nThey have a room for darts and pool great for larger groups.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using list comprehension\n",
    "rowselected = [bool(re.search(\"\\$\\d+[\\d,\\.]*\",s)) for s in df[\"reviews\"]]\n",
    "dfmoney = df[rowselected].copy()\n",
    "dfmoney.reset_index(inplace=True, drop=True)       \n",
    "dfmoney[\"reviews\"][0]   #Just to check the first review we found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d0d1d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There is no other place in town like CSSC. If you are looking for the speakeasy vibe and views of the ped mall this is the place to be. Grab a Silk Road and share the fondue for a perfect date night with ur SO or BFF.\\r\\n\\r\\nDrinks: Silk Road and Pisco sour if you love egg whites. I love egg white in my cocktails because the foam texture which reminds me of a latte. Annabelle lee is refreshing and they have a selection of whisky / bourbon as well if that's your drink of choice.  Cocktails are $10-$12. Also a handful of beers on tap. \\r\\n\\r\\nFood: LOVE the fondue. Melted with apples and caramelizad onions. The poutine is also very popular and I've enjoyed their burger. \\r\\n\\r\\nThey have a room for darts and pool great for larger groups.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using .str method\n",
    "rowselected = df[\"reviews\"].str.contains(\"\\$\\d+[\\d,\\.]*\", regex=True)\n",
    "dfmoney = df[rowselected].copy()\n",
    "dfmoney.reset_index(inplace=True, drop=True)       \n",
    "dfmoney[\"reviews\"][0]   #Just to check the first review we found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce424322",
   "metadata": {},
   "source": [
    "Here, in .str.contains, we set **regex=True** to indicate that we are searching with regular expression rather than search for literal matches. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bc2d8c",
   "metadata": {},
   "source": [
    "Example 2: Use regular expression to remove all special characters except \"_\" in all reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51a37d4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With its jazzy vibes and chill atmosphere, Cli...</td>\n",
       "      <td>5</td>\n",
       "      <td>with its jazzy vibes and chill atmosphere  cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This was an exceptional surprise in Iowa city!...</td>\n",
       "      <td>5</td>\n",
       "      <td>this was an exceptional surprise in iowacity  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There is no other place in town like CSSC. If ...</td>\n",
       "      <td>5</td>\n",
       "      <td>there is no other place in town like cssc  if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tucked away through a narrow staircase like a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>tucked away through a narrow staircase like a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Love. Love. Love. If you're older than the col...</td>\n",
       "      <td>5</td>\n",
       "      <td>love  love  love  if you are older than the co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  ratings  \\\n",
       "0  With its jazzy vibes and chill atmosphere, Cli...        5   \n",
       "1  This was an exceptional surprise in Iowa city!...        5   \n",
       "2  There is no other place in town like CSSC. If ...        5   \n",
       "3  Tucked away through a narrow staircase like a ...        5   \n",
       "4  Love. Love. Love. If you're older than the col...        5   \n",
       "\n",
       "                                         reviews_new  \n",
       "0  with its jazzy vibes and chill atmosphere  cli...  \n",
       "1  this was an exceptional surprise in iowacity  ...  \n",
       "2  there is no other place in town like cssc  if ...  \n",
       "3  tucked away through a narrow staircase like a ...  \n",
       "4  love  love  love  if you are older than the co...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using list comprehension\n",
    "df[\"reviews_new\"] = [re.sub(\"[^\\w\\s]\", ' ' ,s) for s in df[\"reviews_new\"]] \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7cc8e26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With its jazzy vibes and chill atmosphere, Cli...</td>\n",
       "      <td>5</td>\n",
       "      <td>with its jazzy vibes and chill atmosphere  cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This was an exceptional surprise in Iowa city!...</td>\n",
       "      <td>5</td>\n",
       "      <td>this was an exceptional surprise in iowacity  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There is no other place in town like CSSC. If ...</td>\n",
       "      <td>5</td>\n",
       "      <td>there is no other place in town like cssc  if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tucked away through a narrow staircase like a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>tucked away through a narrow staircase like a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Love. Love. Love. If you're older than the col...</td>\n",
       "      <td>5</td>\n",
       "      <td>love  love  love  if you are older than the co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  ratings  \\\n",
       "0  With its jazzy vibes and chill atmosphere, Cli...        5   \n",
       "1  This was an exceptional surprise in Iowa city!...        5   \n",
       "2  There is no other place in town like CSSC. If ...        5   \n",
       "3  Tucked away through a narrow staircase like a ...        5   \n",
       "4  Love. Love. Love. If you're older than the col...        5   \n",
       "\n",
       "                                         reviews_new  \n",
       "0  with its jazzy vibes and chill atmosphere  cli...  \n",
       "1  this was an exceptional surprise in iowacity  ...  \n",
       "2  there is no other place in town like cssc  if ...  \n",
       "3  tucked away through a narrow staircase like a ...  \n",
       "4  love  love  love  if you are older than the co...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using .str method\n",
    "df[\"reviews_new\"] = df[\"reviews_new\"].str.replace(\"[^\\w\\s]\", ' ', regex=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42178d32",
   "metadata": {},
   "source": [
    "Let's compare the new column with the old one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5d5be8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with its jazzy vibes and chill atmosphere  clinton street social club itself may just be the speakeasy of iowacity  it is entrance is through a small door next to shorts burgers and a barber shop  if you do not know what you are looking for  you may never find it  \r\n",
      "\r\n",
      "in all seriousness they mimic new orleans culture and have the most delicious food and creative alcoholic beverages  must try are their beignets  shrimp cocktail  house batterer curds  sweet corn fritters  \r\n",
      "\r\n",
      "for alcoholic drinks  i loved their ramos gin fizz the most  i tend to not like anything where i can taste the alcohol and this one has just the right balance  it is has the right amount of fizz with added foam from the egg whites  very unique compared to the usual bars located downtown  \r\n",
      "\r\n",
      "i had the opportunity to learn how to tend bar from the all knowing bartender joy  that girl definitely knows her alcohol  she made us delicious drinks as told us all about its historical discovery \n"
     ]
    }
   ],
   "source": [
    "print(df[\"reviews_new\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ff9ee1f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With its jazzy vibes and chill atmosphere, Clinton Street Social Club itself may just be the speakeasy of Iowa City. It's entrance is through a small door next to Shorts burgers and a barber shop. If you don't know what you're looking for, you may never find it. \r\n",
      "\r\n",
      "In all seriousness they mimic New Orleans culture and have the most delicious food and creative alcoholic beverages. Must try are their beignets, shrimp cocktail, house-batterer curds, sweet corn fritters! \r\n",
      "\r\n",
      "For alcoholic drinks, I loved their Ramos Gin Fizz the most! I tend to not like anything where I can taste the alcohol and this one has just the right balance. It's has the right amount of fizz with added foam from the egg whites. Very unique compared to the usual bars located downtown. \r\n",
      "\r\n",
      "I had the opportunity to learn how to tend bar from the all knowing bartender Joy, that girl definitely knows her alcohol. She made us delicious drinks as told us all about its historical discovery.\n"
     ]
    }
   ],
   "source": [
    "print(df[\"reviews\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ccd6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
