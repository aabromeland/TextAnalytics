{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd8c1b38",
   "metadata": {},
   "source": [
    "# Sentiment Analysis | BAIS 6100\n",
    "\n",
    "**Instructor: Qihang Lin**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff7f16b",
   "metadata": {},
   "source": [
    "Sentiment analysis is a technique to detect and quantify sentiment polarity (e.g. a positive or negative opinion) within the text data.\n",
    "- A star rating may be used as a sentiment measure of the whole review. However, sentiment analysis can measure the sentiment of each sentence, providing more information than the overall star rating. \n",
    "- Sentiment analysis can gauge customers' response to a product/service in social media, where star ratings are not available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f05bf3c",
   "metadata": {},
   "source": [
    "There are **two major approaches** to sentiment analysis:\n",
    "- Supervised predictive modeling approaches.\n",
    "    - Require each sentence/document being annotated by a sentiment score.  \n",
    "- Unsupervised lexicon-based (rule-based) approaches. (**The focus of this lecture.**)\n",
    "    - Require a lexicon where each word receives a pre-determined sentiment score.\n",
    "    \n",
    "In both approaches, the scores and rules are typically manually assigned by domain experts, linguists, or wisdom of the crowd.\n",
    "\n",
    "Both approaches are sensitive to stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1674ce45",
   "metadata": {},
   "source": [
    "## Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7679147b",
   "metadata": {},
   "source": [
    "Why is Sentiment Analysis difficult to perform in a high quality?\n",
    "1. **Negations.**  \"I don't think this coffee machine is a good choice.\"\n",
    "\n",
    "2. **Multipolarity.** \"The acting was good but the movie could have been better.\"\n",
    "\n",
    "3. **Irony and sarcasm.** \"This phone has an awesome battery back-up of 2 hours.\"\n",
    "\n",
    "4. **Word ambiguity.** \"The story is unpredictable.\" VS \"The steering wheel is unpredictable.\"\n",
    "\n",
    "5. **Others:** Shorthand, abbreviations, different spellings, misspelled words, punctuation, slang, and emojis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810f9c77",
   "metadata": {},
   "source": [
    "To check the performances of different libraries, we generate the following data frame **df1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62188021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This move is bad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This move is not bad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie is good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This movie is not good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This movie is not very good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This movie isn't good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This movie isn't all that good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This movie isn't really all that good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I don't think this movie is good.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     text\n",
       "0                       This move is bad.\n",
       "1                   This move is not bad.\n",
       "2                     This movie is good.\n",
       "3                 This movie is not good.\n",
       "4            This movie is not very good.\n",
       "5                  This movie isn't good.\n",
       "6         This movie isn't all that good.\n",
       "7  This movie isn't really all that good.\n",
       "8       I don't think this movie is good."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_negation=[\"This move is bad.\",\n",
    "                    \"This move is not bad.\",\n",
    "                    \"This movie is good.\",\n",
    "                    \"This movie is not good.\", \n",
    "                    \"This movie is not very good.\",\n",
    "                    \"This movie isn't good.\",\n",
    "                    \"This movie isn't all that good.\",\n",
    "                    \"This movie isn't really all that good.\",\n",
    "                    \"I don't think this movie is good.\"]\n",
    "import pandas as pd\n",
    "#Create a data frame from a list!\n",
    "df1=pd.DataFrame(sentences_negation,columns=[\"text\"])\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62afd70",
   "metadata": {},
   "source": [
    "## AFINN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5ccade",
   "metadata": {},
   "source": [
    "The AFINN lexicon is the simplest lexicons for sentiment analysis. It contains over 3,300+ words with a polarity score between [-5,5] associated with each word. \n",
    "\n",
    "- The complete AFINN lexicons: https://github.com/fnielsen/afinn/tree/master/afinn/data\n",
    "- It can scores some emoticons like :) and :(.\n",
    "- It doesn't handle negation except a few fixed phrases such as \"not good\" and \"not working\".\n",
    "- The total score of a text is simply the summation of the score from each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73137a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting afinn\n",
      "  Downloading afinn-0.1.tar.gz (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hUsing legacy 'setup.py install' for afinn, since package 'wheel' is not installed.\n",
      "Installing collected packages: afinn\n",
      "  Running setup.py install for afinn ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed afinn-0.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Install afinn if running first time\n",
    "#!pip3 install --upgrade afinn \n",
    "from afinn import Afinn\n",
    "afinn = Afinn(emoticons=True)        #Initialize an analyzer\n",
    "afinn.score(\"He is a nice colleague and a great father. :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f609178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>AFINN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This move is bad.</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This move is not bad.</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie is good.</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This movie is not good.</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This movie is not very good.</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This movie isn't good.</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This movie isn't all that good.</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This movie isn't really all that good.</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I don't think this movie is good.</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     text  AFINN\n",
       "0                       This move is bad.   -3.0\n",
       "1                   This move is not bad.   -3.0\n",
       "2                     This movie is good.    3.0\n",
       "3                 This movie is not good.   -2.0\n",
       "4            This movie is not very good.    3.0\n",
       "5                  This movie isn't good.    3.0\n",
       "6         This movie isn't all that good.    3.0\n",
       "7  This movie isn't really all that good.    3.0\n",
       "8       I don't think this movie is good.    3.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"AFINN\"]=[afinn.score(s) for s in df1.text]\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc95ab8",
   "metadata": {},
   "source": [
    "# TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b578e",
   "metadata": {},
   "source": [
    "TextBlob is a library for processing textual data. It is a good alternative to NLTK and can perform common NLP and text mining tasks such as part-of-speech tagging, tokenization, sentiment analysis, classification, and more.\n",
    "\n",
    "In this lecture, we only focus on its functionality in sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bd9de3",
   "metadata": {},
   "source": [
    "TextBlob returns **polarity** of a text based on a lexicon. \n",
    "- The lexicon used (https://github.com/sloria/TextBlob/blob/dev/textblob/en/en-sentiment.xml) \n",
    "- The scores for each word are averaged out to obtain an overall score to a text.\n",
    "- Polarity is normalized between [-1,1],\n",
    "- Negation words reverse the polarity (but not always).\n",
    "- TextBlob score based on emoticons and exclamation mark. \n",
    "- Use \"**intensifier**\" to modify the score of the next word ('very good', 'kind of good').\n",
    "-  A more detailed description of these rules is available: https://planspace.org/20150607-textblob_sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "930c4239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install if running first time\n",
    "#!pip3 install --upgrade textblob\n",
    "#import nltk\n",
    "#nltk.download('movie_reviews')\n",
    "#nltk.download('subjectivity')\n",
    "#nltk.download('vader_lexicon')\n",
    "#nltk.download('sentiwordnet')\n",
    "#nltk.download('wordnet')\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ada4293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5656249999999999"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(\"That is not bad :)!!\").sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "669946e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>AFINN</th>\n",
       "      <th>TextBlob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This move is bad.</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This move is not bad.</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie is good.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This movie is not good.</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This movie is not very good.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.269231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This movie isn't good.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This movie isn't all that good.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This movie isn't really all that good.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I don't think this movie is good.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     text  AFINN  TextBlob\n",
       "0                       This move is bad.   -3.0 -0.700000\n",
       "1                   This move is not bad.   -3.0  0.350000\n",
       "2                     This movie is good.    3.0  0.700000\n",
       "3                 This movie is not good.   -2.0 -0.350000\n",
       "4            This movie is not very good.    3.0 -0.269231\n",
       "5                  This movie isn't good.    3.0  0.700000\n",
       "6         This movie isn't all that good.    3.0  0.700000\n",
       "7  This movie isn't really all that good.    3.0  0.450000\n",
       "8       I don't think this movie is good.    3.0  0.700000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"TextBlob\"]=[TextBlob(s).sentiment.polarity for s in df1.text]\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f00e50e",
   "metadata": {},
   "source": [
    "## VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59832bb",
   "metadata": {},
   "source": [
    "VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in **social media**.\n",
    "- The lexicon used (https://github.com/cjhutto/vaderSentiment/blob/master/vaderSentiment/vader_lexicon.txt)\n",
    "- It works exceedingly well on social media text.\n",
    "- **Positive, Negative and Neutral scores** are generated to represent the proportion of text that falls in these categories. \n",
    "- A **Compound score** is generated using the sum of scores of each word in thex text and it is normalized between [-1, 1]. \n",
    "- More details on VADER scoring methodology: https://github.com/cjhutto/vaderSentiment#about-the-scoring\n",
    "- It exams the **tri-gram** preceding a sentiment-heavy term to detect negation and flip the polarity.\n",
    "- It also scores based on emoticons, emojis, slangs, exclamation mark, and capitalization.\n",
    "- Intensifiers (\"extremely\", \"a little bit\") are used to modify the sentiment scores.\n",
    "- Conjunction (\"but\", \"although\") is used to signal a shift in sentiment polarity. Depending on the conjuntion, the text before or after the conjuction might be weighted higher during the calculation of sentiment score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c06c5475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --upgrade vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "#Initialize VADER sentiment analyzer\n",
    "analyzer=SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f3e0620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.31, 'neu': 0.523, 'pos': 0.167, 'compound': -0.4939}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The output is a dictionary object with four items.\n",
    "analyzer.polarity_scores(\"The food here is great, but the service is horrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d22009c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4939"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To get the compound score only.\n",
    "analyzer.polarity_scores(\"The food here is great, but the service is horrible\")['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "144726fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>AFINN</th>\n",
       "      <th>TextBlob</th>\n",
       "      <th>VADER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This move is bad.</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.5423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This move is not bad.</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.4310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie is good.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This movie is not good.</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.3412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This movie is not very good.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.269231</td>\n",
       "      <td>-0.3865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This movie isn't good.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>-0.3412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This movie isn't all that good.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>-0.3412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This movie isn't really all that good.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.4877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I don't think this movie is good.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     text  AFINN  TextBlob   VADER\n",
       "0                       This move is bad.   -3.0 -0.700000 -0.5423\n",
       "1                   This move is not bad.   -3.0  0.350000  0.4310\n",
       "2                     This movie is good.    3.0  0.700000  0.4404\n",
       "3                 This movie is not good.   -2.0 -0.350000 -0.3412\n",
       "4            This movie is not very good.    3.0 -0.269231 -0.3865\n",
       "5                  This movie isn't good.    3.0  0.700000 -0.3412\n",
       "6         This movie isn't all that good.    3.0  0.700000 -0.3412\n",
       "7  This movie isn't really all that good.    3.0  0.450000  0.4877\n",
       "8       I don't think this movie is good.    3.0  0.700000  0.4404"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"VADER\"]=[analyzer.polarity_scores(s)['compound'] for s in df1.text]\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a4e2c7",
   "metadata": {},
   "source": [
    "## Sentence Tokenization before Sentiment Analysis (To be Discussed in Zoom Meeting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101d82a6",
   "metadata": {},
   "source": [
    "A long document might express mixed sentiment, so it is helpful to apply sentiment analysis to each individual sentence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72ec19a",
   "metadata": {},
   "source": [
    "Some sentiment analyzer (e.g., VADER) is built on short texts (e.g. tweets) and, therefore, does not work well for long documents. When applying that analyzer to a long document, it is better to apply it to each sentence and then take the summation/average of the scores.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bdf503d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dinner and cocktails on a Friday night. Place was packed which I took as a good sign. We ordered classic cocktails (negroni and an old fashioned). I got an americano, which is close to what I ordered, but not right. The server definitely got the name right so the bartender didn\\'t know what she was doing.... The old fashioned was not great.\\r\\nWe ordered the cheese curds and romaine salad to start and they were both fantastic! Both were perfect sharing size and tasted great.\\r\\nFor the second course I ordered wine which came in a short \"juice\" glass. I get that it may fit the theme of the place to serve it that way but it is impossible to enjoy and actually taste red wine when not served in a proper glass. \\r\\nI ordered the veg slider, which as others have said was served on a cold bun with wilted greens on the side. Not terribly appetizing. We had ordered a side of mayo that I added to it that helped a little bit. The cauliflower gratin was a tasty preparation of an otherwise boring veggie.\\r\\nI\\'ll definitely go back and try some other things, I feel like the place has potential. I just know now what they can make work and what they can\\'t....'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "df = pd.read_csv(\"classdata/clinton-street-social-club.csv\",encoding=\"latin-1\")\n",
    "df.reviews[131]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b26163",
   "metadata": {},
   "source": [
    "Review 131 has a star rating of only 2 out of 5, but VADER gives it a high compound score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec9c4171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9903"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.polarity_scores(df.reviews[131])['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2c1bbb",
   "metadata": {},
   "source": [
    "We then tokenize this review into sentences and evaluate each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2256fd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dinner and cocktails on a Friday night.',\n",
       " 'Place was packed which I took as a good sign.',\n",
       " 'We ordered classic cocktails (negroni and an old fashioned).',\n",
       " 'I got an americano, which is close to what I ordered, but not right.',\n",
       " \"The server definitely got the name right so the bartender didn't know what she was doing....\",\n",
       " 'The old fashioned was not great.',\n",
       " 'We ordered the cheese curds and romaine salad to start and they were both fantastic!',\n",
       " 'Both were perfect sharing size and tasted great.',\n",
       " 'For the second course I ordered wine which came in a short \"juice\" glass.',\n",
       " 'I get that it may fit the theme of the place to serve it that way but it is impossible to enjoy and actually taste red wine when not served in a proper glass.',\n",
       " 'I ordered the veg slider, which as others have said was served on a cold bun with wilted greens on the side.',\n",
       " 'Not terribly appetizing.',\n",
       " 'We had ordered a side of mayo that I added to it that helped a little bit.',\n",
       " 'The cauliflower gratin was a tasty preparation of an otherwise boring veggie.',\n",
       " \"I'll definitely go back and try some other things, I feel like the place has potential.\",\n",
       " \"I just know now what they can make work and what they can't....\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_temp = tokenize.sent_tokenize(df.reviews[131])\n",
    "sentences_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ea52aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>VADER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dinner and cocktails on a Friday night.</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Place was packed which I took as a good sign.</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We ordered classic cocktails (negroni and an o...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I got an americano, which is close to what I o...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The server definitely got the name right so th...</td>\n",
       "      <td>0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The old fashioned was not great.</td>\n",
       "      <td>-0.5096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>We ordered the cheese curds and romaine salad ...</td>\n",
       "      <td>0.5983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Both were perfect sharing size and tasted great.</td>\n",
       "      <td>0.8910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>For the second course I ordered wine which cam...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I get that it may fit the theme of the place t...</td>\n",
       "      <td>0.7227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I ordered the veg slider, which as others have...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Not terribly appetizing.</td>\n",
       "      <td>0.4449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>We had ordered a side of mayo that I added to ...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The cauliflower gratin was a tasty preparation...</td>\n",
       "      <td>-0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I'll definitely go back and try some other thi...</td>\n",
       "      <td>0.6369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I just know now what they can make work and wh...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Sentence   VADER\n",
       "0             Dinner and cocktails on a Friday night.  0.0000\n",
       "1       Place was packed which I took as a good sign.  0.4404\n",
       "2   We ordered classic cocktails (negroni and an o...  0.0000\n",
       "3   I got an americano, which is close to what I o...  0.0000\n",
       "4   The server definitely got the name right so th...  0.4019\n",
       "5                    The old fashioned was not great. -0.5096\n",
       "6   We ordered the cheese curds and romaine salad ...  0.5983\n",
       "7    Both were perfect sharing size and tasted great.  0.8910\n",
       "8   For the second course I ordered wine which cam...  0.0000\n",
       "9   I get that it may fit the theme of the place t...  0.7227\n",
       "10  I ordered the veg slider, which as others have...  0.0000\n",
       "11                           Not terribly appetizing.  0.4449\n",
       "12  We had ordered a side of mayo that I added to ...  0.0000\n",
       "13  The cauliflower gratin was a tasty preparation... -0.2263\n",
       "14  I'll definitely go back and try some other thi...  0.6369\n",
       "15  I just know now what they can make work and wh...  0.0000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_temp = tokenize.sent_tokenize(df.reviews[131])\n",
    "dftemp=pd.DataFrame(sentences_temp,columns=[\"Sentence\"])\n",
    "dftemp[\"VADER\"]=[analyzer.polarity_scores(s)['compound'] for s in dftemp.Sentence]\n",
    "dftemp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d33587a",
   "metadata": {},
   "source": [
    "Once we have created the sentiment score (by any of the three methods) for each row, we can sort the data frame by the score to find the most positive/negative rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09cd7fab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The old fashioned was not great.',\n",
       " 'The cauliflower gratin was a tasty preparation of an otherwise boring veggie.',\n",
       " 'Dinner and cocktails on a Friday night.',\n",
       " 'We ordered classic cocktails (negroni and an old fashioned).',\n",
       " 'I got an americano, which is close to what I ordered, but not right.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftemp.sort_values(by=\"VADER\",ascending=True,inplace=True)\n",
    "dftemp.reset_index(drop=True,inplace=True)\n",
    "list(dftemp.Sentence[0:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
